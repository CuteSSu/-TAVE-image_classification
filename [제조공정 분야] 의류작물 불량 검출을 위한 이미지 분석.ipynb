{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [1] 실습 환경 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\anaconda3\\envs\\conda\\lib\\site-packages (4.5.5.62)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\anaconda3\\envs\\conda\\lib\\site-packages (from opencv-python) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "import shutil\n",
    "import random\n",
    "import string\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DEFECT = 'dataset/Defect_images/'\n",
    "PATH_MASK = 'dataset/Mask_images/'\n",
    "PATH_NODEFECT = 'dataset/NODefect_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "\n",
    "defect_list = glob.glob(PATH_DEFECT + '*.png')\n",
    "mask_list = glob.glob(PATH_MASK + '*.png')\n",
    "pass_list = glob.glob(PATH_NODEFECT + '**/*.png')\n",
    "\n",
    "# Match defect-mask pairs\n",
    "new_defect_list = list()\n",
    "new_mask_list = list()\n",
    "for defect in defect_list:\n",
    "    num = defect.split('/')[-1].split('_')[0]\n",
    "    for mask in mask_list:\n",
    "        num_mask = mask.split('/')[-1].split('_')[0]\n",
    "        if num == num_mask:\n",
    "            new_defect_list.append(defect)\n",
    "            new_mask_list.append(mask)\n",
    "            break\n",
    "defect_list = new_defect_list\n",
    "mask_list = new_mask_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 첫 발송 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first dataset given\n",
    "if os.path.exists('dataset/1') is False:\n",
    "    os.mkdir('dataset/1')\n",
    "for file_name in pass_list + defect_list:\n",
    "    if random.randint(0, 9) < 2:\n",
    "        barcode = ''.join(random.choices(string.ascii_letters + string.digits, k=16))\n",
    "        shutil.copy2(file_name, 'dataset/1/' + barcode + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 두번째 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The second dataset\n",
    "if os.path.exists('dataset/2') is False:\n",
    "    os.mkdir('dataset/2')\n",
    "if os.path.exists('dataset/2/OK') is False:\n",
    "    os.mkdir('dataset/2/OK')\n",
    "if os.path.exists('dataset/2/FAIL') is False:\n",
    "    os.mkdir('dataset/2/FAIL')\n",
    "idx = 0\n",
    "for file_name in pass_list:\n",
    "    img = cv2.imread(file_name)\n",
    "    height, width, _ = img.shape\n",
    "    step = height // 2\n",
    "\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height and random.randint(0, 9) < 2:\n",
    "            patch = img[:, w:w+height, :]\n",
    "            cv2.imwrite('dataset/2/OK/%04d.png' % idx, patch)\n",
    "            idx += 1 \n",
    "\n",
    "patch_list = list()\n",
    "for item in zip(defect_list, mask_list):\n",
    "    defect, mask = item\n",
    "\n",
    "    img_d = cv2.imread(defect)\n",
    "    img_m = cv2.imread(mask)\n",
    "\n",
    "    height, width, _ = img_d.shape\n",
    "    step = height // 2\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height:\n",
    "            patch = img_d[:, w:w+height, :]\n",
    "            patch_d = img_m[:, w:w+height, :]\n",
    "            if patch_d.sum() > 0:\n",
    "                patch_list.append(patch)\n",
    "\n",
    "random.shuffle(patch_list)\n",
    "patch_list_fraction = patch_list[:len(patch_list)//3]\n",
    "for idx, patch in enumerate(patch_list_fraction):\n",
    "    cv2.imwrite('dataset/2/FAIL/%04d.png' % idx, patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 세번째 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The third dataset\n",
    "if os.path.exists('dataset/3') is False:\n",
    "    os.mkdir('dataset/3')\n",
    "if os.path.exists('dataset/3/OK') is False:\n",
    "    os.mkdir('dataset/3/OK')\n",
    "if os.path.exists('dataset/3/FAIL') is False:\n",
    "    os.mkdir('dataset/3/FAIL')\n",
    "if os.path.exists('dataset/3/MASK') is False:\n",
    "    os.mkdir('dataset/3/MASK')\n",
    "idx = 0\n",
    "for file_name in pass_list:\n",
    "    img = cv2.imread(file_name)\n",
    "    height, width, _ = img.shape\n",
    "    step = height // 2\n",
    "\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height and random.randint(0, 9) < 3:\n",
    "            patch = img[:, w:w+height, :]\n",
    "            cv2.imwrite('dataset/3/OK/%04d.png' % idx, patch)\n",
    "            idx += 1 \n",
    "\n",
    "patch_pair_list = list()\n",
    "for item in zip(defect_list, mask_list):\n",
    "    defect, mask = item\n",
    "\n",
    "    img_d = cv2.imread(defect)\n",
    "    img_m = cv2.imread(mask)\n",
    "\n",
    "    height, width, _ = img_d.shape\n",
    "    step = height // 2\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height:\n",
    "            patch = img_d[:, w:w+height, :]\n",
    "            patch_d = img_m[:, w:w+height, :]\n",
    "\n",
    "            if patch_d.sum() > 0:\n",
    "                patch_pair_list.append((patch, patch_d))\n",
    "\n",
    "random.shuffle(patch_pair_list)\n",
    "for idx, pair in enumerate(patch_pair_list):\n",
    "    patch, patch_d = pair\n",
    "    cv2.imwrite('dataset/3/FAIL/%04d.png' % idx, patch)\n",
    "    cv2.imwrite('dataset/3/MASK/%04d.png' % idx, patch_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실전 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test dataset\n",
    "if os.path.exists('dataset/input_data') is False:\n",
    "    os.mkdir('dataset/input_data')\n",
    "if os.path.exists('dataset/output_csv') is False:\n",
    "    os.mkdir('dataset/output_csv')\n",
    "    \n",
    "idx = 0\n",
    "for file_name in pass_list:\n",
    "    img = cv2.imread(file_name)\n",
    "    height, width, _ = img.shape\n",
    "    step = height // 2\n",
    "\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height and random.randint(0, 9) < 5:\n",
    "            patch = img[:, w:w+height, :]\n",
    "            cv2.imwrite('dataset/input_data/ok_%04d.png' % idx, patch)\n",
    "            idx += 1 \n",
    "\n",
    "patch_pair_list = list()\n",
    "for item in zip(defect_list, mask_list):\n",
    "    defect, mask = item\n",
    "\n",
    "    img_d = cv2.imread(defect)\n",
    "    img_m = cv2.imread(mask)\n",
    "\n",
    "    height, width, _ = img_d.shape\n",
    "    step = height // 2\n",
    "    for i in range(width // step):\n",
    "        w = i * step\n",
    "        if w < width - height:\n",
    "            patch = img_d[:, w:w+height, :]\n",
    "            patch_d = img_m[:, w:w+height, :]\n",
    "\n",
    "            if patch_d.sum() > 0:\n",
    "                patch_pair_list.append((patch, patch_d))\n",
    "\n",
    "random.shuffle(patch_pair_list)\n",
    "for idx, pair in enumerate(patch_pair_list):\n",
    "    patch, patch_d = pair\n",
    "    cv2.imwrite('dataset/input_data/fail_%04d.png' % idx, patch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [2] 실행 가능성 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 단순한 모델 설정\n",
    "EPOCHS = 10\n",
    "\n",
    "DATASET_PATH = 'dataset/2/'\n",
    "DATASET_OK_PATTERN = DATASET_PATH + 'OK/*.png'\n",
    "DATASET_FAIL_PATTERN = DATASET_PATH + 'FAIL/*.png'\n",
    "\n",
    "RESULT_SAVE_PATH = 'results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단순한 모델 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    return Sequential([Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)), #tensorflow 버전업으로 코드 변경\n",
    "                       MaxPool2D(),\n",
    "                       Conv2D(64, (3, 3), activation='relu'),\n",
    "                       MaxPool2D(),\n",
    "                       Conv2D(128, (3, 3), activation='relu'),\n",
    "                       MaxPool2D(),\n",
    "                       Conv2D(256, (3, 3), activation='relu'),\n",
    "                       MaxPool2D(),\n",
    "                       Flatten(),\n",
    "                       Dense(1, activation='sigmoid')])## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_name):\n",
    "    img = tf.io.read_file(file_name)\n",
    "    img = tf.image.decode_png(img, channels=1) #tensorflow 버전업으로 코드 변경\n",
    "    return tf.image.convert_image_dtype(img, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_list = glob.glob(DATASET_OK_PATTERN)\n",
    "ds_ok = tf.data.Dataset.list_files(ok_list)\n",
    "ds_ok_label = tf.data.Dataset.from_tensor_slices([0] * len(ok_list))\n",
    "\n",
    "ds_ok = ds_ok.map(preprocess)\n",
    "ds_ok = tf.data.Dataset.zip((ds_ok, ds_ok_label))\n",
    "\n",
    "fail_list = glob.glob(DATASET_FAIL_PATTERN)\n",
    "ds_fail = tf.data.Dataset.list_files(fail_list)\n",
    "ds_fail_label = tf.data.Dataset.from_tensor_slices([1] * len(fail_list))\n",
    "\n",
    "ds_fail = ds_fail.map(preprocess)\n",
    "ds_fail = tf.data.Dataset.zip((ds_fail, ds_fail_label))## Train, Valid 데이터셋 나누기\n",
    "\n",
    "ds = tf.data.Dataset.concatenate(ds_ok, ds_fail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Valid 데이터셋 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = len(ok_list) + len(fail_list)\n",
    "train_size = int(ds_size * 0.7)\n",
    "\n",
    "ds = ds.shuffle(ds_size)\n",
    "ds_train = ds.take(train_size).shuffle(1024, reshuffle_each_iteration=True).batch(32)\n",
    "ds_valid = ds.skip(train_size).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성 및 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(ds_train, validation_data=ds_valid, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdir(path):\n",
    "    if os.path.exists(path) is False:\n",
    "        os.mkdir(path)\n",
    "\n",
    "mkdir(RESULT_SAVE_PATH)\n",
    "mkdir(RESULT_SAVE_PATH + '/TP')\n",
    "mkdir(RESULT_SAVE_PATH + '/TN')\n",
    "mkdir(RESULT_SAVE_PATH + '/FP')\n",
    "mkdir(RESULT_SAVE_PATH + '/FN')\n",
    "\n",
    "index = 0\n",
    "for imgs, labels in ds_valid:\n",
    "    preds = model.predict(imgs)\n",
    "    for idx in range(imgs.shape[0]):\n",
    "        gt = labels[idx].numpy()\n",
    "        y = preds[idx]\n",
    "        \n",
    "        if gt == 1 and y > 0.5:\n",
    "            path = RESULT_SAVE_PATH + '/TP'\n",
    "        elif gt == 1 and y <= 0.5:\n",
    "            path = RESULT_SAVE_PATH + '/FN'\n",
    "        elif gt == 0 and y > 0.5:\n",
    "            path = RESULT_SAVE_PATH + '/FP'\n",
    "        else:\n",
    "            path = RESULT_SAVE_PATH + '/TN'\n",
    "            \n",
    "        cv2.imwrite(path + '/%.4f_%04d.png' % (y, index), imgs[idx].numpy() * 255)\n",
    "        index +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [3] 데이터 정리하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecord Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths and Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_OK_PATTERN = 'dataset/3/OK/*.png'\n",
    "DATASET_FAIL_PATTERN = 'dataset/3/FAIL/*.png'\n",
    "\n",
    "TFRECORD_PATH = 'tfrecords/'\n",
    "IMAGE_PER_TFRECORD = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_list = glob.glob(DATASET_OK_PATTERN)\n",
    "fail_list = glob.glob(DATASET_FAIL_PATTERN)\n",
    "\n",
    "num_ok = len(ok_list)\n",
    "num_fail = len(fail_list)\n",
    "\n",
    "# Oversampling\n",
    "fail_list_new = list()\n",
    "for _ in range(num_ok // num_fail):\n",
    "    fail_list_new += fail_list\n",
    "fail_list_new += fail_list[: num_ok % num_fail]\n",
    "fail_list = fail_list_new\n",
    "\n",
    "ok_label = [0] * len(ok_list)\n",
    "fail_label = [1] * len(fail_list)\n",
    "\n",
    "file_list = ok_list + fail_list\n",
    "label_list = ok_label + fail_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecord functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def image_example(image_string, label):\n",
    "    image_shape = tf.image.decode_image(image_string).shape\n",
    "\n",
    "    feature = {\n",
    "        'height': _int64_feature(image_shape[0]),\n",
    "        'width': _int64_feature(image_shape[1]),\n",
    "        'depth': _int64_feature(image_shape[2]),\n",
    "        'label': _int64_feature(label),\n",
    "        'image_raw': _bytes_feature(image_string),\n",
    "    }\n",
    "\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write TFRecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(TFRECORD_PATH) is False:\n",
    "    os.mkdir(TFRECORD_PATH)\n",
    "\n",
    "num_tfrecords = len(file_list) // IMAGE_PER_TFRECORD\n",
    "if len(file_list) % IMAGE_PER_TFRECORD != 0:\n",
    "    num_tfrecords += 1\n",
    "\n",
    "for idx in range(num_tfrecords):\n",
    "    idx0 = idx * IMAGE_PER_TFRECORD\n",
    "    idx1 = idx0 + IMAGE_PER_TFRECORD\n",
    "    record_file = TFRECORD_PATH + '%05d.tfrecords' % idx\n",
    "    with tf.io.TFRecordWriter(record_file) as writer:\n",
    "        for filename, label in zip(file_list[idx0:idx1],\n",
    "                                   label_list[idx0:idx1]):\n",
    "            image_string = open(filename, 'rb').read()\n",
    "            tf_example = image_example(image_string, label)\n",
    "            writer.write(tf_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [4] 모델 학습 및 검증하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow_addons in c:\\anaconda3\\envs\\conda\\lib\\site-packages (0.15.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in c:\\anaconda3\\envs\\conda\\lib\\site-packages (from tensorflow_addons) (2.13.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\anaconda3\\envs\\conda\\lib\\site-packages (3.5.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\anaconda3\\envs\\conda\\lib\\site-packages (from matplotlib) (9.0.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\anaconda3\\envs\\conda\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\anaconda3\\envs\\conda\\lib\\site-packages (from matplotlib) (1.21.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\anaconda3\\envs\\conda\\lib\\site-packages (from matplotlib) (4.28.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\anaconda3\\envs\\conda\\lib\\site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\anaconda3\\envs\\conda\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\anaconda3\\envs\\conda\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\anaconda3\\envs\\conda\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda3\\envs\\conda\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa #안되면 pip install \n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, Concatenate, Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "RESULT_SAVE_PATH = 'results/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception-based 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model():\n",
    "    def inception(filters):\n",
    "        def subnetwork(x):\n",
    "            h1 = Conv2D(filters, (1, 1), padding='same', activation='relu')(x)\n",
    "            h1 = MaxPool2D()(h1)\n",
    "            \n",
    "            h2 = Conv2D(filters // 2, (1, 1), padding='same', activation='relu')(x)\n",
    "            h2 = Conv2D(filters, (3, 3), padding='same', activation='relu')(h2)\n",
    "            h2 = MaxPool2D()(h2)\n",
    "            \n",
    "            h3 = Conv2D(filters // 2, (1, 1), padding='same', activation='relu')(x)\n",
    "            h3 = Conv2D(filters, (5, 5), padding='same', activation='relu')(h3)\n",
    "            h3 = MaxPool2D()(h3)\n",
    "            return Concatenate()([h1, h2, h3])\n",
    "        return subnetwork\n",
    "    \n",
    "    x = tf.keras.Input(shape=(256, 256, 3))\n",
    "    h = inception(16)(x)\n",
    "    h = inception(32)(h)\n",
    "    h = inception(32)(h)\n",
    "    h = inception(32)(h)\n",
    "    h = inception(32)(h)\n",
    "    h = Flatten()(h)\n",
    "    h = Dense(1024, activation='relu')(h)\n",
    "    y = Dense(1, activation='sigmoid')(h)\n",
    "    return tf.keras.Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data 전처리 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img):\n",
    "    return tf.image.convert_image_dtype(img, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentation(img, label):\n",
    "    def flip(x):\n",
    "        x = tf.image.random_flip_left_right(x)\n",
    "        x = tf.image.random_flip_up_down(x)\n",
    "        return x\n",
    "    \n",
    "    def rotate(x):\n",
    "        x = tf.cond(tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32) > 0.5,\n",
    "                   lambda: tfa.image.rotate(x,\n",
    "                                       tf.random.uniform(shape=[], minval=0.0, maxval=360.0, dtype=tf.float32),\n",
    "                                       interpolation='BILINEAR'),\n",
    "                   lambda: x)\n",
    "        return x\n",
    "    \n",
    "    def translation(x):\n",
    "        dx = tf.random.uniform(shape=[], minval=-10.0, maxval=10.0, dtype=tf.float32)\n",
    "        dy = tf.random.uniform(shape=[], minval=-10.0, maxval=10.0, dtype=tf.float32)\n",
    "        x = tf.cond(tf.random.uniform(shape=[], minval=0.0, maxval=1.0, dtype=tf.float32) > 0.5,\n",
    "                    lambda: tfa.image.transform(x,\n",
    "                                                [0, 0, dx, 0, 0, dy, 0, 0],\n",
    "                                                interpolation='BILINEAR'),\n",
    "                    lambda: x)\n",
    "        return x\n",
    "    \n",
    "    img = flip(img)\n",
    "    img = rotate(img)\n",
    "    img = translation(img)\n",
    "           \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFRecords 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tffiles = glob.glob('tfrecords/*')\n",
    "raw_image_dataset = tf.data.TFRecordDataset(tffiles)\n",
    "\n",
    "image_feature_description = {\n",
    "    'height': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'width': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
    "}\n",
    "\n",
    "def _parse_image_function(example_proto):\n",
    "    return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n",
    "def _parse_image_label(parsed_dataset):\n",
    "    return preprocess(tf.image.decode_png(parsed_dataset['image_raw'])), parsed_dataset['label']\n",
    "\n",
    "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "dataset = parsed_image_dataset.map(_parse_image_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_size = 0\n",
    "for _ in dataset:\n",
    "    ds_size += 1\n",
    "\n",
    "train_size = int(ds_size * 0.7)\n",
    "\n",
    "ds = dataset.shuffle(ds_size)\n",
    "ds_train = ds.take(train_size).shuffle(1024, reshuffle_each_iteration=True).prefetch(1024).batch(32).map(augmentation)\n",
    "ds_valid = ds.skip(train_size).prefetch(1024).batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30, verbose=1)\n",
    "history = model.fit(ds_train,\n",
    "                    validation_data=ds_valid,\n",
    "                    epochs=EPOCHS,\n",
    "                    callbacks=[earlystopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 결과 Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(loss, 'ro-')\n",
    "plt.plot(val_loss, 'bo-')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/inception_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [5] 프로그램 전달하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 배치형 동작 프로그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터, Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRES_LEVEL = 0.5 #0.5이하면 ok / 1에 가까울 수록 fail\n",
    "\n",
    "INPUT_PATH = 'dataset/input_data/'\n",
    "CSV_PATH = 'dataset/output_csv/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('model/inception_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 입력 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(file_name):\n",
    "    img = tf.io.read_file(file_name)\n",
    "    img = tf.image.decode_image(img)\n",
    "    return tf.image.convert_image_dtype(img, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 입력 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(INPUT_PATH + '*.png')\n",
    "dataset = tf.data.Dataset.list_files(file_list).map(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 알고리즘 구동 및 CSV 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0.3540363311767578\n",
      "Inference Time: 0.09731197357177734\n",
      "Inference Time: 0.11469411849975586\n",
      "Inference Time: 0.13763189315795898\n",
      "Inference Time: 0.12566208839416504\n",
      "Inference Time: 0.12965631484985352\n",
      "Inference Time: 0.11269617080688477\n",
      "Inference Time: 0.11967778205871582\n",
      "Inference Time: 0.12318587303161621\n",
      "Inference Time: 0.12744998931884766\n",
      "Inference Time: 0.12466549873352051\n",
      "Inference Time: 0.12766742706298828\n",
      "Inference Time: 0.12167477607727051\n",
      "Inference Time: 0.16419267654418945\n",
      "Inference Time: 0.1795179843902588\n",
      "Inference Time: 0.1436145305633545\n",
      "Inference Time: 0.1436152458190918\n",
      "Inference Time: 0.14660930633544922\n",
      "Inference Time: 0.15358948707580566\n",
      "Inference Time: 0.18103480339050293\n",
      "Inference Time: 0.2194216251373291\n",
      "Inference Time: 0.14760422706604004\n",
      "Inference Time: 0.18602609634399414\n",
      "Inference Time: 0.2492361068725586\n",
      "Inference Time: 0.2528502941131592\n",
      "Inference Time: 0.15059423446655273\n",
      "Inference Time: 0.18202996253967285\n",
      "Inference Time: 0.226393461227417\n",
      "Inference Time: 0.2802884578704834\n",
      "Inference Time: 0.24636244773864746\n",
      "Inference Time: 0.2573113441467285\n",
      "Inference Time: 0.13962483406066895\n",
      "Inference Time: 0.11169767379760742\n",
      "Inference Time: 0.3193848133087158\n",
      "Inference Time: 0.19646883010864258\n",
      "Inference Time: 0.1326138973236084\n",
      "Inference Time: 0.12617897987365723\n",
      "Inference Time: 0.27535367012023926\n",
      "Inference Time: 0.40248823165893555\n",
      "Inference Time: 0.13420987129211426\n",
      "Inference Time: 0.2359757423400879\n",
      "Inference Time: 0.2323627471923828\n",
      "Inference Time: 0.13315916061401367\n",
      "Inference Time: 0.4080240726470947\n",
      "Inference Time: 0.21741914749145508\n",
      "Inference Time: 0.15259027481079102\n",
      "Inference Time: 0.14561057090759277\n",
      "Inference Time: 0.3121631145477295\n",
      "Inference Time: 0.1969752311706543\n",
      "Inference Time: 0.15809249877929688\n",
      "Inference Time: 0.10871315002441406\n",
      "Inference Time: 0.1097111701965332\n",
      "Inference Time: 0.12965106964111328\n",
      "Inference Time: 0.19103145599365234\n",
      "Inference Time: 0.24434113502502441\n",
      "Inference Time: 0.11469292640686035\n",
      "Inference Time: 0.11070370674133301\n",
      "Inference Time: 0.17954587936401367\n",
      "Inference Time: 0.30218958854675293\n",
      "Inference Time: 0.1503291130065918\n",
      "Inference Time: 0.15558290481567383\n",
      "Inference Time: 0.1211860179901123\n",
      "Inference Time: 0.11568927764892578\n",
      "Inference Time: 0.11469268798828125\n",
      "Inference Time: 0.11768698692321777\n",
      "Inference Time: 0.155104398727417\n",
      "Inference Time: 0.14811372756958008\n",
      "Inference Time: 0.1406235694885254\n",
      "Inference Time: 0.12566494941711426\n",
      "Inference Time: 0.11169981956481934\n",
      "Inference Time: 0.1166846752166748\n",
      "Inference Time: 0.10970592498779297\n",
      "Inference Time: 0.1525895595550537\n",
      "Inference Time: 0.14911317825317383\n",
      "Inference Time: 0.15059590339660645\n",
      "Inference Time: 0.12466764450073242\n",
      "Inference Time: 0.11605691909790039\n",
      "Inference Time: 0.11512398719787598\n",
      "Inference Time: 0.1117241382598877\n",
      "Inference Time: 0.11469459533691406\n",
      "Inference Time: 0.1446084976196289\n",
      "Inference Time: 0.1575791835784912\n",
      "Inference Time: 0.13962650299072266\n",
      "Inference Time: 0.1386270523071289\n",
      "Inference Time: 0.11810064315795898\n",
      "Inference Time: 0.19946646690368652\n",
      "Inference Time: 0.26529574394226074\n",
      "Inference Time: 0.16356205940246582\n",
      "Inference Time: 0.3032360076904297\n",
      "Inference Time: 0.3261268138885498\n",
      "Inference Time: 0.14560842514038086\n",
      "Inference Time: 0.173539400100708\n",
      "Inference Time: 0.32770776748657227\n",
      "Inference Time: 0.2031104564666748\n",
      "Inference Time: 0.3119325637817383\n",
      "Inference Time: 0.12266993522644043\n",
      "Inference Time: 0.28882527351379395\n",
      "Inference Time: 0.1954786777496338\n",
      "Inference Time: 0.14062237739562988\n",
      "Inference Time: 0.18949460983276367\n",
      "Inference Time: 0.38477611541748047\n",
      "Inference Time: 0.19627642631530762\n",
      "Inference Time: 0.1859149932861328\n",
      "Inference Time: 0.15059614181518555\n",
      "Inference Time: 0.1980891227722168\n",
      "Inference Time: 0.21792888641357422\n",
      "Inference Time: 0.22340178489685059\n",
      "Inference Time: 0.21941113471984863\n",
      "Inference Time: 0.18550348281860352\n",
      "Inference Time: 0.19152450561523438\n",
      "Inference Time: 0.45792150497436523\n",
      "Inference Time: 0.2954368591308594\n",
      "Inference Time: 0.17552852630615234\n",
      "Inference Time: 0.154587984085083\n",
      "Inference Time: 0.1705491542816162\n",
      "Inference Time: 0.13862991333007812\n",
      "Inference Time: 0.16113042831420898\n",
      "Inference Time: 0.17107415199279785\n",
      "Inference Time: 0.18351054191589355\n",
      "Inference Time: 0.3815128803253174\n",
      "Inference Time: 0.3171529769897461\n",
      "Inference Time: 0.3919858932495117\n",
      "Inference Time: 0.3687136173248291\n",
      "Inference Time: 0.3409538269042969\n",
      "Inference Time: 0.17755699157714844\n",
      "Inference Time: 0.19050025939941406\n",
      "Inference Time: 0.1735389232635498\n",
      "Inference Time: 0.1505897045135498\n",
      "Inference Time: 0.16356110572814941\n",
      "Inference Time: 0.16555523872375488\n",
      "Inference Time: 0.3171522617340088\n",
      "Inference Time: 0.31568384170532227\n",
      "Inference Time: 0.3809487819671631\n",
      "Inference Time: 0.38973355293273926\n",
      "Inference Time: 0.25507664680480957\n",
      "Inference Time: 0.3207054138183594\n",
      "Inference Time: 0.3110227584838867\n",
      "Inference Time: 0.1625959873199463\n",
      "Inference Time: 0.1266615390777588\n",
      "Inference Time: 0.19015121459960938\n",
      "Inference Time: 0.2563169002532959\n",
      "Inference Time: 0.17650675773620605\n",
      "Inference Time: 0.18051671981811523\n",
      "Inference Time: 0.17453551292419434\n",
      "Inference Time: 0.23688054084777832\n",
      "Inference Time: 0.23536968231201172\n",
      "Inference Time: 0.20696020126342773\n",
      "Inference Time: 0.2852356433868408\n",
      "Inference Time: 0.25525355339050293\n",
      "Inference Time: 0.22039103507995605\n",
      "Inference Time: 0.20046448707580566\n",
      "Inference Time: 0.1735367774963379\n",
      "Inference Time: 0.16555309295654297\n",
      "Inference Time: 0.18849444389343262\n",
      "Inference Time: 0.1894986629486084\n",
      "Inference Time: 0.1928260326385498\n",
      "Inference Time: 0.20099234580993652\n",
      "Inference Time: 0.4009270668029785\n",
      "Inference Time: 0.3945152759552002\n",
      "Inference Time: 0.24534106254577637\n",
      "Inference Time: 0.31200456619262695\n",
      "Inference Time: 0.22890090942382812\n",
      "Inference Time: 0.198472261428833\n",
      "Inference Time: 0.17006516456604004\n",
      "Inference Time: 0.1914808750152588\n",
      "Inference Time: 0.14760470390319824\n",
      "Inference Time: 0.21941161155700684\n",
      "Inference Time: 0.16954755783081055\n",
      "Inference Time: 0.1515946388244629\n",
      "Inference Time: 0.1636791229248047\n",
      "Inference Time: 0.14561009407043457\n",
      "Inference Time: 0.32868313789367676\n",
      "Inference Time: 0.33220362663269043\n",
      "Inference Time: 0.28582096099853516\n",
      "Inference Time: 0.3291168212890625\n",
      "Inference Time: 0.4693591594696045\n",
      "Inference Time: 0.1870255470275879\n",
      "Inference Time: 0.17253875732421875\n",
      "Inference Time: 0.1535332202911377\n",
      "Inference Time: 0.17005658149719238\n",
      "Inference Time: 0.17752957344055176\n",
      "Inference Time: 0.1615581512451172\n",
      "Inference Time: 0.16456031799316406\n",
      "Inference Time: 0.1575767993927002\n",
      "Inference Time: 0.12367033958435059\n",
      "Inference Time: 0.14711904525756836\n",
      "Inference Time: 0.14361357688903809\n",
      "Inference Time: 0.1356372833251953\n",
      "Inference Time: 0.12243843078613281\n",
      "Inference Time: 0.14014363288879395\n",
      "Inference Time: 0.14005494117736816\n",
      "Inference Time: 0.13364243507385254\n",
      "Inference Time: 0.11469244956970215\n",
      "Inference Time: 0.19448089599609375\n",
      "Inference Time: 0.12466573715209961\n",
      "Inference Time: 0.1156914234161377\n",
      "Inference Time: 0.11520576477050781\n",
      "Inference Time: 0.12854838371276855\n",
      "Inference Time: 0.13463807106018066\n",
      "Inference Time: 0.1216742992401123\n",
      "Inference Time: 0.12932562828063965\n",
      "Inference Time: 0.16307568550109863\n",
      "Inference Time: 0.1296675205230713\n",
      "Inference Time: 0.12466597557067871\n",
      "Inference Time: 0.11668658256530762\n",
      "Inference Time: 0.1376326084136963\n",
      "Inference Time: 0.14560961723327637\n",
      "Inference Time: 0.15059614181518555\n",
      "Inference Time: 0.13163185119628906\n",
      "Inference Time: 0.1461191177368164\n",
      "Inference Time: 0.12567663192749023\n",
      "Inference Time: 0.12765789031982422\n",
      "Inference Time: 0.11369609832763672\n",
      "Inference Time: 0.14412975311279297\n",
      "Inference Time: 0.12666082382202148\n",
      "Inference Time: 0.1266613006591797\n",
      "Inference Time: 0.11469459533691406\n",
      "Inference Time: 0.1386265754699707\n",
      "Inference Time: 0.5127818584442139\n",
      "Inference Time: 0.1186819076538086\n",
      "Inference Time: 0.12267065048217773\n",
      "Inference Time: 0.11569070816040039\n",
      "Inference Time: 0.14107418060302734\n",
      "Inference Time: 0.1261742115020752\n",
      "Inference Time: 0.11768412590026855\n",
      "Inference Time: 0.11668896675109863\n",
      "Inference Time: 0.11967873573303223\n",
      "Inference Time: 0.12566280364990234\n",
      "Inference Time: 0.11469340324401855\n",
      "Inference Time: 0.14560914039611816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0.11619901657104492\n",
      "Inference Time: 0.1242666244506836\n",
      "Inference Time: 0.11469149589538574\n",
      "Inference Time: 0.11670064926147461\n",
      "Inference Time: 0.1326436996459961\n",
      "Inference Time: 0.11253976821899414\n",
      "Inference Time: 0.11320638656616211\n",
      "Inference Time: 0.13364434242248535\n",
      "Inference Time: 0.1466045379638672\n",
      "Inference Time: 0.1236717700958252\n",
      "Inference Time: 0.1296539306640625\n",
      "Inference Time: 0.1356353759765625\n",
      "Inference Time: 0.14261889457702637\n",
      "Inference Time: 0.12466549873352051\n",
      "Inference Time: 0.12467265129089355\n",
      "Inference Time: 0.11768460273742676\n",
      "Inference Time: 0.13065218925476074\n",
      "Inference Time: 0.1186835765838623\n",
      "Inference Time: 0.13364338874816895\n",
      "Inference Time: 0.1296520233154297\n",
      "Inference Time: 0.12820005416870117\n",
      "Inference Time: 0.12666058540344238\n",
      "Inference Time: 0.1376330852508545\n",
      "Inference Time: 0.11967897415161133\n",
      "Inference Time: 0.13913774490356445\n",
      "Inference Time: 0.11681365966796875\n",
      "Inference Time: 0.11220765113830566\n",
      "Inference Time: 0.13065099716186523\n",
      "Inference Time: 0.11868071556091309\n",
      "Inference Time: 0.11669230461120605\n",
      "Inference Time: 0.11569023132324219\n",
      "Inference Time: 0.36418962478637695\n",
      "Inference Time: 0.1216733455657959\n",
      "Inference Time: 0.18550348281860352\n",
      "Inference Time: 0.17552995681762695\n",
      "Inference Time: 0.16356110572814941\n",
      "Inference Time: 0.13464117050170898\n",
      "Inference Time: 0.12671256065368652\n",
      "Inference Time: 0.1107025146484375\n",
      "Inference Time: 0.1964716911315918\n",
      "Inference Time: 0.17536091804504395\n",
      "Inference Time: 0.1650552749633789\n",
      "Inference Time: 0.14661121368408203\n",
      "Inference Time: 0.13962721824645996\n",
      "Inference Time: 0.16057062149047852\n",
      "Inference Time: 0.17852163314819336\n",
      "Inference Time: 0.16256475448608398\n",
      "Inference Time: 0.14130353927612305\n",
      "Inference Time: 0.3300778865814209\n",
      "Inference Time: 0.22311973571777344\n",
      "Inference Time: 0.19311237335205078\n",
      "Inference Time: 0.19849538803100586\n",
      "Inference Time: 0.35109448432922363\n",
      "Inference Time: 0.2847559452056885\n",
      "Inference Time: 0.2543210983276367\n",
      "Inference Time: 0.17254018783569336\n",
      "Inference Time: 0.19148707389831543\n",
      "Inference Time: 0.12366962432861328\n",
      "Inference Time: 0.15658044815063477\n",
      "Inference Time: 0.12466692924499512\n",
      "Inference Time: 0.15267395973205566\n",
      "Inference Time: 0.1386280059814453\n",
      "Inference Time: 0.15957164764404297\n",
      "Inference Time: 0.15459418296813965\n",
      "Inference Time: 0.15361404418945312\n",
      "Inference Time: 0.11170101165771484\n",
      "Inference Time: 0.1246650218963623\n",
      "Inference Time: 0.11568975448608398\n",
      "Inference Time: 0.14760637283325195\n",
      "Inference Time: 0.1545851230621338\n",
      "Inference Time: 0.1495983600616455\n",
      "Inference Time: 0.15464115142822266\n",
      "Inference Time: 0.15159392356872559\n",
      "Inference Time: 0.12367510795593262\n",
      "Inference Time: 0.1326451301574707\n",
      "Inference Time: 0.14513564109802246\n",
      "Inference Time: 0.1526176929473877\n",
      "Inference Time: 0.14561057090759277\n",
      "Inference Time: 0.1386263370513916\n",
      "Inference Time: 0.15857386589050293\n",
      "Inference Time: 0.12067651748657227\n",
      "Inference Time: 0.12765812873840332\n",
      "Inference Time: 0.11369466781616211\n",
      "Inference Time: 0.13116955757141113\n",
      "Inference Time: 0.15658068656921387\n",
      "Inference Time: 0.16954612731933594\n",
      "Inference Time: 0.15947985649108887\n",
      "Inference Time: 0.16356158256530762\n",
      "Inference Time: 0.13563799858093262\n",
      "Inference Time: 0.12466740608215332\n",
      "Inference Time: 0.13463854789733887\n",
      "Inference Time: 0.1406245231628418\n",
      "Inference Time: 0.15757417678833008\n",
      "Inference Time: 0.1246635913848877\n",
      "Inference Time: 0.14461922645568848\n",
      "Inference Time: 0.11843204498291016\n",
      "Inference Time: 0.11723184585571289\n",
      "Inference Time: 0.12717509269714355\n",
      "Inference Time: 0.15709304809570312\n",
      "Inference Time: 0.13364100456237793\n",
      "Inference Time: 0.14461207389831543\n",
      "Inference Time: 0.13065004348754883\n",
      "Inference Time: 0.14661097526550293\n",
      "Inference Time: 0.13763189315795898\n",
      "Inference Time: 0.1685495376586914\n",
      "Inference Time: 0.16256403923034668\n",
      "Inference Time: 0.11668896675109863\n",
      "Inference Time: 0.13464069366455078\n",
      "Inference Time: 0.13614201545715332\n",
      "Inference Time: 0.12366676330566406\n",
      "Inference Time: 0.11269831657409668\n",
      "Inference Time: 0.11070466041564941\n",
      "Inference Time: 0.12865519523620605\n",
      "Inference Time: 0.11668801307678223\n",
      "Inference Time: 0.13463878631591797\n",
      "Inference Time: 0.11369609832763672\n",
      "Inference Time: 0.12467026710510254\n",
      "Inference Time: 0.12765717506408691\n",
      "Inference Time: 0.12525296211242676\n",
      "Inference Time: 0.11306881904602051\n",
      "Inference Time: 0.12366700172424316\n",
      "Inference Time: 0.1107022762298584\n",
      "Inference Time: 0.11269736289978027\n",
      "Inference Time: 0.12067794799804688\n",
      "Inference Time: 0.11691927909851074\n",
      "Inference Time: 0.11269783973693848\n",
      "Inference Time: 0.11469340324401855\n",
      "Inference Time: 0.11768627166748047\n",
      "Inference Time: 0.11568808555603027\n",
      "Inference Time: 0.11369585990905762\n",
      "Inference Time: 0.11269831657409668\n",
      "Inference Time: 0.11400294303894043\n",
      "Inference Time: 0.2101292610168457\n",
      "Inference Time: 0.27529120445251465\n",
      "Inference Time: 0.18350839614868164\n",
      "Inference Time: 0.18051528930664062\n",
      "Inference Time: 0.16755056381225586\n",
      "Inference Time: 0.18350791931152344\n",
      "Inference Time: 0.2543182373046875\n",
      "Inference Time: 0.159559965133667\n",
      "Inference Time: 0.1964733600616455\n",
      "Inference Time: 0.16557836532592773\n",
      "Inference Time: 0.13663339614868164\n",
      "Inference Time: 0.1327517032623291\n",
      "Inference Time: 0.1192929744720459\n",
      "Inference Time: 0.1269545555114746\n",
      "Inference Time: 0.13116002082824707\n",
      "Inference Time: 0.15558552742004395\n",
      "Inference Time: 0.1326441764831543\n",
      "Inference Time: 0.11169886589050293\n",
      "Inference Time: 0.11868166923522949\n",
      "Inference Time: 0.20245718955993652\n",
      "Inference Time: 0.1845088005065918\n",
      "Inference Time: 0.18949270248413086\n",
      "Inference Time: 0.4019594192504883\n",
      "Inference Time: 0.36261940002441406\n",
      "Inference Time: 0.7149906158447266\n",
      "Inference Time: 0.21999287605285645\n",
      "Inference Time: 0.16508150100708008\n",
      "Inference Time: 0.19547462463378906\n",
      "Inference Time: 0.2020263671875\n",
      "Inference Time: 0.22592401504516602\n",
      "Inference Time: 0.35704541206359863\n",
      "Inference Time: 0.3198812007904053\n",
      "Inference Time: 0.357527494430542\n",
      "Inference Time: 0.3207969665527344\n",
      "Inference Time: 0.25170183181762695\n",
      "Inference Time: 0.23601746559143066\n",
      "Inference Time: 0.20259666442871094\n",
      "Inference Time: 0.1650524139404297\n",
      "Inference Time: 0.234696626663208\n",
      "Inference Time: 0.18650102615356445\n",
      "Inference Time: 0.1466071605682373\n",
      "Inference Time: 0.2338864803314209\n",
      "Inference Time: 0.21008682250976562\n",
      "Inference Time: 0.19549274444580078\n",
      "Inference Time: 0.19004583358764648\n",
      "Inference Time: 0.21198487281799316\n",
      "Inference Time: 0.20696115493774414\n",
      "Inference Time: 0.20245099067687988\n",
      "Inference Time: 0.3408389091491699\n",
      "Inference Time: 0.2971827983856201\n",
      "Inference Time: 0.24321889877319336\n",
      "Inference Time: 0.3061797618865967\n",
      "Inference Time: 0.24387788772583008\n",
      "Inference Time: 0.18853020668029785\n",
      "Inference Time: 0.19200348854064941\n",
      "Inference Time: 0.14361357688903809\n",
      "Inference Time: 0.2513260841369629\n",
      "Inference Time: 0.2249150276184082\n",
      "Inference Time: 0.15599799156188965\n",
      "Inference Time: 0.15458440780639648\n",
      "Inference Time: 0.1798386573791504\n",
      "Inference Time: 0.15065765380859375\n",
      "Inference Time: 0.2024843692779541\n",
      "Inference Time: 0.18350768089294434\n",
      "Inference Time: 0.16057729721069336\n",
      "Inference Time: 0.17754602432250977\n",
      "Inference Time: 0.28524351119995117\n",
      "Inference Time: 0.1296522617340088\n",
      "Inference Time: 0.1236722469329834\n",
      "Inference Time: 0.12545251846313477\n",
      "Inference Time: 0.12891697883605957\n",
      "Inference Time: 0.13316106796264648\n",
      "Inference Time: 0.13065147399902344\n",
      "Inference Time: 0.11569023132324219\n",
      "Inference Time: 0.14062237739562988\n",
      "Inference Time: 0.12067770957946777\n",
      "Inference Time: 0.12666106224060059\n",
      "Inference Time: 0.11668872833251953\n",
      "Inference Time: 0.13614559173583984\n",
      "Inference Time: 0.13095664978027344\n",
      "Inference Time: 0.12373089790344238\n",
      "Inference Time: 0.12067723274230957\n",
      "Inference Time: 0.13023090362548828\n",
      "Inference Time: 0.14081668853759766\n",
      "Inference Time: 0.12267160415649414\n",
      "Inference Time: 0.1266617774963379\n",
      "Inference Time: 0.12586760520935059\n",
      "Inference Time: 0.1326427459716797\n",
      "Inference Time: 0.12067818641662598\n",
      "Inference Time: 0.1545853614807129\n",
      "Inference Time: 0.11868047714233398\n",
      "Inference Time: 0.12566256523132324\n",
      "Inference Time: 0.11070466041564941\n",
      "Inference Time: 0.12566351890563965\n",
      "Inference Time: 0.12618112564086914\n",
      "Inference Time: 0.13614606857299805\n",
      "Inference Time: 0.1281723976135254\n",
      "Inference Time: 0.1321580410003662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0.11867976188659668\n",
      "Inference Time: 0.12865900993347168\n",
      "Inference Time: 0.12366843223571777\n",
      "Inference Time: 0.133650541305542\n",
      "Inference Time: 0.15159368515014648\n",
      "Inference Time: 0.1371462345123291\n",
      "Inference Time: 0.14760231971740723\n",
      "Inference Time: 0.14316725730895996\n",
      "Inference Time: 0.14162230491638184\n",
      "Inference Time: 0.14761066436767578\n",
      "Inference Time: 0.13466596603393555\n",
      "Inference Time: 0.16209697723388672\n",
      "Inference Time: 0.14162135124206543\n",
      "Inference Time: 0.176530122756958\n",
      "Inference Time: 0.15957331657409668\n",
      "Inference Time: 0.12366890907287598\n",
      "Inference Time: 0.12765765190124512\n",
      "Inference Time: 0.1401360034942627\n",
      "Inference Time: 0.15459656715393066\n",
      "Inference Time: 0.13364267349243164\n",
      "Inference Time: 0.16606616973876953\n",
      "Inference Time: 0.13217616081237793\n",
      "Inference Time: 0.16555571556091309\n",
      "Inference Time: 0.13962340354919434\n",
      "Inference Time: 0.12366819381713867\n",
      "Inference Time: 0.11967897415161133\n",
      "Inference Time: 0.19547653198242188\n",
      "Inference Time: 0.1880791187286377\n",
      "Inference Time: 0.1495981216430664\n",
      "Inference Time: 0.12566280364990234\n",
      "Inference Time: 0.14360594749450684\n",
      "Inference Time: 0.13962674140930176\n",
      "Inference Time: 0.1261765956878662\n",
      "Inference Time: 0.1226952075958252\n",
      "Inference Time: 0.1172020435333252\n",
      "Inference Time: 0.11967897415161133\n",
      "Inference Time: 0.11070418357849121\n",
      "Inference Time: 0.11568784713745117\n",
      "Inference Time: 0.12028050422668457\n",
      "Inference Time: 0.11469364166259766\n",
      "Inference Time: 0.11569094657897949\n",
      "Inference Time: 0.12066507339477539\n",
      "Inference Time: 0.11469459533691406\n",
      "Inference Time: 0.10971188545227051\n",
      "Inference Time: 0.14062094688415527\n",
      "Inference Time: 0.1204986572265625\n",
      "Inference Time: 0.12160921096801758\n",
      "Inference Time: 0.11693835258483887\n",
      "Inference Time: 0.12192511558532715\n",
      "Inference Time: 0.1107029914855957\n",
      "Inference Time: 0.12267327308654785\n",
      "Inference Time: 0.10970592498779297\n",
      "Inference Time: 0.11070442199707031\n",
      "Inference Time: 0.10970616340637207\n",
      "Inference Time: 0.1276555061340332\n",
      "Inference Time: 0.13411974906921387\n",
      "Inference Time: 0.11620521545410156\n",
      "Inference Time: 0.13614797592163086\n",
      "Inference Time: 0.13364171981811523\n",
      "Inference Time: 0.11960387229919434\n",
      "Inference Time: 0.13164472579956055\n",
      "Inference Time: 0.1186830997467041\n",
      "Inference Time: 0.13363981246948242\n",
      "Inference Time: 0.13364076614379883\n",
      "Inference Time: 0.11469340324401855\n",
      "Inference Time: 0.11668682098388672\n",
      "Inference Time: 0.11668801307678223\n",
      "Inference Time: 0.12069439888000488\n",
      "Inference Time: 0.11619925498962402\n",
      "Inference Time: 0.1172025203704834\n",
      "Inference Time: 0.12297296524047852\n",
      "Inference Time: 0.11668610572814941\n",
      "Inference Time: 0.11469507217407227\n",
      "Inference Time: 0.10870933532714844\n",
      "Inference Time: 0.1122133731842041\n",
      "Inference Time: 0.11320877075195312\n",
      "Inference Time: 0.11820030212402344\n",
      "Inference Time: 0.11170172691345215\n",
      "Inference Time: 0.12423467636108398\n",
      "Inference Time: 0.11768364906311035\n",
      "Inference Time: 0.1107025146484375\n",
      "Inference Time: 0.10771012306213379\n",
      "Inference Time: 0.11369514465332031\n",
      "Inference Time: 0.12167644500732422\n",
      "Inference Time: 0.10979342460632324\n",
      "Inference Time: 0.10921692848205566\n",
      "Inference Time: 0.1186823844909668\n",
      "Inference Time: 0.11070489883422852\n",
      "Inference Time: 0.1276559829711914\n",
      "Inference Time: 0.1181943416595459\n",
      "Inference Time: 0.12218284606933594\n",
      "Inference Time: 0.1261744499206543\n",
      "Inference Time: 0.18204998970031738\n",
      "Inference Time: 0.11169981956481934\n",
      "Inference Time: 0.12665915489196777\n",
      "Inference Time: 0.11668682098388672\n",
      "Inference Time: 0.1874980926513672\n",
      "Inference Time: 0.25388312339782715\n",
      "Inference Time: 0.12568068504333496\n",
      "Inference Time: 0.1326441764831543\n",
      "Inference Time: 0.12170195579528809\n",
      "Inference Time: 0.21642088890075684\n",
      "Inference Time: 0.16455864906311035\n",
      "Inference Time: 0.11949801445007324\n",
      "Inference Time: 0.1321561336517334\n",
      "Inference Time: 0.1181948184967041\n",
      "Inference Time: 0.10970854759216309\n",
      "Inference Time: 0.11269521713256836\n",
      "Inference Time: 0.11967825889587402\n",
      "Inference Time: 0.13763117790222168\n",
      "Inference Time: 0.1296546459197998\n",
      "Inference Time: 0.12865662574768066\n",
      "Inference Time: 0.11868119239807129\n",
      "Inference Time: 0.12865471839904785\n",
      "Inference Time: 0.11568927764892578\n",
      "Inference Time: 0.12870264053344727\n",
      "Inference Time: 0.10822224617004395\n",
      "Inference Time: 0.11520242691040039\n",
      "Inference Time: 0.11768364906311035\n",
      "Inference Time: 0.10671234130859375\n",
      "Inference Time: 0.11469030380249023\n",
      "Inference Time: 0.12865567207336426\n",
      "Inference Time: 0.13962435722351074\n",
      "Inference Time: 0.12266945838928223\n",
      "Inference Time: 0.13364195823669434\n",
      "Inference Time: 0.12466597557067871\n",
      "Inference Time: 0.13862872123718262\n",
      "Inference Time: 0.12665963172912598\n",
      "Inference Time: 0.11598014831542969\n",
      "Inference Time: 0.13514995574951172\n",
      "Inference Time: 0.10970449447631836\n",
      "Inference Time: 0.12666034698486328\n",
      "Inference Time: 0.1136941909790039\n",
      "Inference Time: 0.12965607643127441\n",
      "Inference Time: 0.11768436431884766\n",
      "Inference Time: 0.11369609832763672\n",
      "Inference Time: 0.13463711738586426\n",
      "Inference Time: 0.13016700744628906\n",
      "Inference Time: 0.12865924835205078\n",
      "Inference Time: 0.11469340324401855\n",
      "Inference Time: 0.11228561401367188\n",
      "Inference Time: 0.11364173889160156\n",
      "Inference Time: 0.1406230926513672\n",
      "Inference Time: 0.14313387870788574\n",
      "Inference Time: 0.11369442939758301\n",
      "Inference Time: 0.11269855499267578\n",
      "Inference Time: 0.11768507957458496\n",
      "Inference Time: 0.13280344009399414\n",
      "Inference Time: 0.11569046974182129\n",
      "Inference Time: 0.1266617774963379\n",
      "Inference Time: 0.12176752090454102\n",
      "Inference Time: 0.12666082382202148\n",
      "Inference Time: 0.11669182777404785\n",
      "Inference Time: 0.11369538307189941\n",
      "Inference Time: 0.12865519523620605\n",
      "Inference Time: 0.10822105407714844\n",
      "Inference Time: 0.12123751640319824\n",
      "Inference Time: 0.10980033874511719\n",
      "Inference Time: 0.12007904052734375\n",
      "Inference Time: 0.1172020435333252\n",
      "Inference Time: 0.12965011596679688\n",
      "Inference Time: 0.15059542655944824\n",
      "Inference Time: 0.11768555641174316\n",
      "Inference Time: 0.11668729782104492\n",
      "Inference Time: 0.10970354080200195\n",
      "Inference Time: 0.11967754364013672\n",
      "Inference Time: 0.11819791793823242\n",
      "Inference Time: 0.1376357078552246\n",
      "Inference Time: 0.1406230926513672\n",
      "Inference Time: 0.1236720085144043\n",
      "Inference Time: 0.12318038940429688\n",
      "Inference Time: 0.13962578773498535\n",
      "Inference Time: 0.11369562149047852\n",
      "Inference Time: 0.11469459533691406\n",
      "Inference Time: 0.13364195823669434\n",
      "Inference Time: 0.11668753623962402\n",
      "Inference Time: 0.15059661865234375\n",
      "Inference Time: 0.1271684169769287\n",
      "Inference Time: 0.11967849731445312\n",
      "Inference Time: 0.11170125007629395\n",
      "Inference Time: 0.12067508697509766\n",
      "Inference Time: 0.11469364166259766\n",
      "Inference Time: 0.11822986602783203\n",
      "Inference Time: 0.11466002464294434\n",
      "Inference Time: 0.11868023872375488\n",
      "Inference Time: 0.12267231941223145\n",
      "Inference Time: 0.11369562149047852\n",
      "Inference Time: 0.11768293380737305\n",
      "Inference Time: 0.1156914234161377\n",
      "Inference Time: 0.1166839599609375\n",
      "Inference Time: 0.2378849983215332\n",
      "Inference Time: 0.12067770957946777\n",
      "Inference Time: 0.12721657752990723\n",
      "Inference Time: 0.12566447257995605\n",
      "Inference Time: 0.11321377754211426\n",
      "Inference Time: 0.1211855411529541\n",
      "Inference Time: 0.11170148849487305\n",
      "Inference Time: 0.13663291931152344\n",
      "Inference Time: 0.12765884399414062\n",
      "Inference Time: 0.13364195823669434\n",
      "Inference Time: 0.16755199432373047\n",
      "Inference Time: 0.16407346725463867\n",
      "Inference Time: 0.18103528022766113\n",
      "Inference Time: 0.1236732006072998\n",
      "Inference Time: 0.14261960983276367\n",
      "Inference Time: 0.18226957321166992\n",
      "Inference Time: 0.1426246166229248\n",
      "Inference Time: 0.15424871444702148\n",
      "Inference Time: 0.15358853340148926\n",
      "Inference Time: 0.11469411849975586\n",
      "Inference Time: 0.14162015914916992\n",
      "Inference Time: 0.1186830997467041\n",
      "Inference Time: 0.13614749908447266\n",
      "Inference Time: 0.12466692924499512\n",
      "Inference Time: 0.14121556282043457\n",
      "Inference Time: 0.11768531799316406\n",
      "Inference Time: 0.13364195823669434\n",
      "Inference Time: 0.12665987014770508\n",
      "Inference Time: 0.12965130805969238\n",
      "Inference Time: 0.11469435691833496\n",
      "Inference Time: 0.12665939331054688\n",
      "Inference Time: 0.1216738224029541\n",
      "Inference Time: 0.12090420722961426\n",
      "Inference Time: 0.11868119239807129\n",
      "Inference Time: 0.11469244956970215\n",
      "Inference Time: 0.12816691398620605\n",
      "Inference Time: 0.14777231216430664\n",
      "Inference Time: 0.12192893028259277\n",
      "Inference Time: 0.11569046974182129\n",
      "Inference Time: 0.14860033988952637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0.12318873405456543\n",
      "Inference Time: 0.13715529441833496\n",
      "Inference Time: 0.1406242847442627\n",
      "Inference Time: 0.12067890167236328\n",
      "Inference Time: 0.11668539047241211\n",
      "Inference Time: 0.12067580223083496\n",
      "Inference Time: 0.13663315773010254\n",
      "Inference Time: 0.1386251449584961\n",
      "Inference Time: 0.12865543365478516\n",
      "Inference Time: 0.15387558937072754\n",
      "Inference Time: 0.1216726303100586\n",
      "Inference Time: 0.13064837455749512\n",
      "Inference Time: 0.1296532154083252\n",
      "Inference Time: 0.12417960166931152\n",
      "Inference Time: 0.13313961029052734\n",
      "Inference Time: 0.10970544815063477\n",
      "Inference Time: 0.13164472579956055\n",
      "Inference Time: 0.2641618251800537\n",
      "Inference Time: 0.11073946952819824\n",
      "Inference Time: 0.10402631759643555\n",
      "Inference Time: 0.1057133674621582\n",
      "Inference Time: 0.11170578002929688\n",
      "Inference Time: 0.10870957374572754\n",
      "Inference Time: 0.10671663284301758\n",
      "Inference Time: 0.10571527481079102\n",
      "Inference Time: 0.11668586730957031\n",
      "Inference Time: 0.12518000602722168\n",
      "Inference Time: 0.11420822143554688\n",
      "Inference Time: 0.10970616340637207\n",
      "Inference Time: 0.11968016624450684\n",
      "Inference Time: 0.14960241317749023\n",
      "Inference Time: 0.12366962432861328\n",
      "Inference Time: 0.1406233310699463\n",
      "Inference Time: 0.13463354110717773\n",
      "Inference Time: 0.1396329402923584\n",
      "Inference Time: 0.11768698692321777\n",
      "Inference Time: 0.12067723274230957\n",
      "Inference Time: 0.13364148139953613\n",
      "Inference Time: 0.11496782302856445\n",
      "Inference Time: 0.12167501449584961\n",
      "Inference Time: 0.11170005798339844\n",
      "Inference Time: 0.1144404411315918\n",
      "Inference Time: 0.10870909690856934\n",
      "Inference Time: 0.11269807815551758\n",
      "Inference Time: 0.10970592498779297\n",
      "Inference Time: 0.1077108383178711\n",
      "Inference Time: 0.11320781707763672\n",
      "Inference Time: 0.11668896675109863\n",
      "Inference Time: 0.11070442199707031\n",
      "Inference Time: 0.1156928539276123\n",
      "Inference Time: 0.12177038192749023\n",
      "Inference Time: 0.10997200012207031\n",
      "Inference Time: 0.11021828651428223\n",
      "Inference Time: 0.15957307815551758\n",
      "Inference Time: 0.13962626457214355\n",
      "Inference Time: 0.12666034698486328\n",
      "Inference Time: 0.11768698692321777\n",
      "Inference Time: 0.1356372833251953\n",
      "Inference Time: 0.12366724014282227\n",
      "Inference Time: 0.11369490623474121\n",
      "Inference Time: 0.10372209548950195\n",
      "Inference Time: 0.12067818641662598\n",
      "Inference Time: 0.11369514465332031\n",
      "Inference Time: 0.1373147964477539\n",
      "Inference Time: 0.11349010467529297\n",
      "Inference Time: 0.12917399406433105\n",
      "Inference Time: 0.11619424819946289\n",
      "Inference Time: 0.1186819076538086\n",
      "Inference Time: 0.12666106224060059\n",
      "Inference Time: 0.11867952346801758\n",
      "Inference Time: 0.14561033248901367\n",
      "Inference Time: 0.14162063598632812\n",
      "Inference Time: 0.11269879341125488\n",
      "Inference Time: 0.11967730522155762\n",
      "Inference Time: 0.13364362716674805\n",
      "Inference Time: 0.12030029296875\n",
      "Inference Time: 0.12367725372314453\n",
      "Inference Time: 0.11321067810058594\n",
      "Inference Time: 0.11902093887329102\n",
      "Inference Time: 0.11420607566833496\n",
      "Inference Time: 0.10970735549926758\n",
      "Inference Time: 0.12965178489685059\n",
      "Inference Time: 0.10970735549926758\n",
      "Inference Time: 0.11169981956481934\n",
      "Inference Time: 0.1296532154083252\n",
      "Inference Time: 0.12665867805480957\n",
      "Inference Time: 0.11320710182189941\n",
      "Inference Time: 0.11719822883605957\n",
      "Inference Time: 0.13364458084106445\n",
      "Inference Time: 0.2024860382080078\n",
      "Inference Time: 0.14421820640563965\n",
      "Inference Time: 0.12318849563598633\n",
      "Inference Time: 0.10921978950500488\n",
      "Inference Time: 0.15301799774169922\n",
      "Inference Time: 0.16456198692321777\n",
      "Inference Time: 0.13165044784545898\n",
      "Inference Time: 0.11070466041564941\n",
      "Inference Time: 0.12965106964111328\n",
      "Inference Time: 0.11768484115600586\n",
      "Inference Time: 0.10870933532714844\n",
      "Inference Time: 0.10822582244873047\n",
      "Inference Time: 0.11669301986694336\n",
      "Inference Time: 0.11668753623962402\n",
      "Inference Time: 0.11170053482055664\n",
      "Inference Time: 0.10965609550476074\n",
      "Inference Time: 0.11719894409179688\n",
      "Inference Time: 0.11688923835754395\n",
      "Inference Time: 0.11577653884887695\n",
      "Inference Time: 0.10870742797851562\n",
      "Inference Time: 0.1107034683227539\n",
      "Inference Time: 0.1934819221496582\n",
      "Inference Time: 0.16755032539367676\n",
      "Inference Time: 0.15858817100524902\n",
      "Inference Time: 0.1416161060333252\n",
      "Inference Time: 0.12419676780700684\n",
      "Inference Time: 0.1077108383178711\n",
      "Inference Time: 0.10970759391784668\n",
      "Inference Time: 0.11568927764892578\n",
      "Inference Time: 0.11620020866394043\n",
      "Inference Time: 0.16156697273254395\n",
      "Inference Time: 0.14361858367919922\n",
      "Inference Time: 0.16256403923034668\n",
      "Inference Time: 0.14560961723327637\n",
      "Inference Time: 0.11070418357849121\n",
      "Inference Time: 0.12566351890563965\n",
      "Inference Time: 0.1401386260986328\n",
      "Inference Time: 0.16056370735168457\n",
      "Inference Time: 0.11568903923034668\n",
      "Inference Time: 0.13763952255249023\n",
      "Inference Time: 0.1656026840209961\n",
      "Inference Time: 0.10622668266296387\n",
      "Inference Time: 0.10471892356872559\n",
      "Inference Time: 0.1296532154083252\n",
      "Inference Time: 0.13563990592956543\n",
      "Inference Time: 0.16156792640686035\n",
      "Inference Time: 0.11568975448608398\n",
      "Inference Time: 0.12566781044006348\n",
      "Inference Time: 0.11919307708740234\n",
      "Inference Time: 0.15461111068725586\n",
      "Inference Time: 0.1384446620941162\n",
      "Inference Time: 0.1396312713623047\n",
      "Inference Time: 0.12150406837463379\n",
      "Inference Time: 0.13064956665039062\n",
      "Inference Time: 0.11668658256530762\n",
      "Inference Time: 0.13862848281860352\n",
      "Inference Time: 0.12765812873840332\n",
      "Inference Time: 0.1326441764831543\n",
      "Inference Time: 0.14361572265625\n",
      "Inference Time: 0.15511512756347656\n",
      "Inference Time: 0.12666058540344238\n",
      "Inference Time: 0.12766695022583008\n",
      "Inference Time: 0.1436171531677246\n",
      "Inference Time: 0.14212989807128906\n",
      "Inference Time: 0.14760375022888184\n",
      "Inference Time: 0.13863658905029297\n",
      "Inference Time: 0.12267184257507324\n",
      "Inference Time: 0.12765908241271973\n",
      "Inference Time: 0.1326444149017334\n",
      "Inference Time: 0.1216740608215332\n",
      "Inference Time: 0.12366771697998047\n",
      "Inference Time: 0.14860153198242188\n",
      "Inference Time: 0.1904897689819336\n",
      "Inference Time: 0.147613525390625\n",
      "Inference Time: 0.1406235694885254\n",
      "Inference Time: 0.13263607025146484\n",
      "Inference Time: 0.24235153198242188\n",
      "Inference Time: 0.36354684829711914\n",
      "Inference Time: 0.25809788703918457\n",
      "Inference Time: 0.12067675590515137\n",
      "Inference Time: 0.12267160415649414\n",
      "Inference Time: 0.12841320037841797\n",
      "Inference Time: 0.16762685775756836\n",
      "Inference Time: 0.12765884399414062\n",
      "Inference Time: 0.12167191505432129\n",
      "Inference Time: 0.1186838150024414\n",
      "Inference Time: 0.14660906791687012\n",
      "Inference Time: 0.1326436996459961\n",
      "Inference Time: 0.13464927673339844\n",
      "Inference Time: 0.11420130729675293\n",
      "Inference Time: 0.12267851829528809\n",
      "Inference Time: 0.11269783973693848\n",
      "Inference Time: 0.11469316482543945\n",
      "Inference Time: 0.11719846725463867\n",
      "Inference Time: 0.20447969436645508\n",
      "Inference Time: 0.1468658447265625\n",
      "Inference Time: 0.1281743049621582\n",
      "Inference Time: 0.2403578758239746\n",
      "Inference Time: 0.24445056915283203\n",
      "Inference Time: 0.21936368942260742\n",
      "Inference Time: 0.15221762657165527\n",
      "Inference Time: 0.18849492073059082\n",
      "Inference Time: 0.1575772762298584\n",
      "Inference Time: 0.22638487815856934\n",
      "Inference Time: 0.23043179512023926\n",
      "Inference Time: 0.2513284683227539\n",
      "Inference Time: 0.15159296989440918\n",
      "Inference Time: 0.13364148139953613\n",
      "Inference Time: 0.15259075164794922\n",
      "Inference Time: 0.26190781593322754\n",
      "Inference Time: 0.36188292503356934\n",
      "Inference Time: 0.1825118064880371\n",
      "Inference Time: 0.12665915489196777\n",
      "Inference Time: 0.19547724723815918\n",
      "Inference Time: 0.14959359169006348\n",
      "Inference Time: 0.12965059280395508\n",
      "Inference Time: 0.12865376472473145\n",
      "Inference Time: 0.14860272407531738\n",
      "Inference Time: 0.12765836715698242\n",
      "Inference Time: 0.14461421966552734\n",
      "Inference Time: 0.17708468437194824\n",
      "Inference Time: 0.16359543800354004\n",
      "Inference Time: 0.3136768341064453\n",
      "Inference Time: 0.2792518138885498\n",
      "Inference Time: 0.23038291931152344\n",
      "Inference Time: 0.21748137474060059\n",
      "Inference Time: 0.2418668270111084\n",
      "Inference Time: 0.3041839599609375\n",
      "Inference Time: 0.19701313972473145\n",
      "Inference Time: 0.23930931091308594\n",
      "Inference Time: 0.2952103614807129\n",
      "Inference Time: 0.25731396675109863\n",
      "Inference Time: 0.32813096046447754\n",
      "Inference Time: 0.3510599136352539\n",
      "Inference Time: 0.20245575904846191\n",
      "Inference Time: 0.2672853469848633\n",
      "Inference Time: 0.25232410430908203\n",
      "Inference Time: 0.19447612762451172\n",
      "Inference Time: 0.16456127166748047\n",
      "Inference Time: 0.14162111282348633\n",
      "Inference Time: 0.14362645149230957\n",
      "Inference Time: 0.1216728687286377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0.13914012908935547\n",
      "Inference Time: 0.13220977783203125\n",
      "Inference Time: 0.15658044815063477\n",
      "Inference Time: 0.12366867065429688\n",
      "Inference Time: 0.12816739082336426\n",
      "Inference Time: 0.13109350204467773\n",
      "Inference Time: 0.1156911849975586\n",
      "Inference Time: 0.11867976188659668\n",
      "Inference Time: 0.11967897415161133\n",
      "Inference Time: 0.14162158966064453\n",
      "Inference Time: 0.15059542655944824\n",
      "Inference Time: 0.12566375732421875\n",
      "Inference Time: 0.1216738224029541\n",
      "Inference Time: 0.1176900863647461\n",
      "Inference Time: 0.11668753623962402\n",
      "Inference Time: 0.13405537605285645\n",
      "Inference Time: 0.11469173431396484\n",
      "Inference Time: 0.13067984580993652\n",
      "Inference Time: 0.12218594551086426\n",
      "Inference Time: 0.12865543365478516\n",
      "Inference Time: 0.20046281814575195\n",
      "Inference Time: 0.16954755783081055\n",
      "Inference Time: 0.12466645240783691\n",
      "Inference Time: 0.12367033958435059\n",
      "Inference Time: 0.13515019416809082\n",
      "Inference Time: 0.14561128616333008\n",
      "Inference Time: 0.1276566982269287\n",
      "Inference Time: 0.12666106224060059\n",
      "Inference Time: 0.16606593132019043\n",
      "Inference Time: 0.1665782928466797\n",
      "Inference Time: 0.148118257522583\n",
      "Inference Time: 0.12167477607727051\n",
      "Inference Time: 0.1107034683227539\n",
      "Inference Time: 0.11967754364013672\n",
      "Inference Time: 0.12067818641662598\n",
      "Inference Time: 0.13364171981811523\n",
      "Inference Time: 0.21593785285949707\n",
      "Inference Time: 0.17852020263671875\n",
      "Inference Time: 0.1874988079071045\n",
      "Inference Time: 0.11145830154418945\n",
      "Inference Time: 0.1271669864654541\n",
      "Inference Time: 0.11902976036071777\n",
      "Inference Time: 0.11919498443603516\n",
      "Inference Time: 0.11070394515991211\n",
      "Inference Time: 0.11070418357849121\n",
      "Inference Time: 0.10970473289489746\n",
      "Inference Time: 0.12167549133300781\n",
      "Inference Time: 0.10906028747558594\n",
      "Inference Time: 0.12665915489196777\n",
      "Inference Time: 0.16455984115600586\n",
      "Inference Time: 0.13663387298583984\n",
      "Inference Time: 0.1336498260498047\n",
      "Inference Time: 0.15553069114685059\n",
      "Inference Time: 0.12717127799987793\n",
      "Inference Time: 0.1173243522644043\n",
      "Inference Time: 0.11919188499450684\n",
      "Inference Time: 0.15657854080200195\n",
      "Inference Time: 0.14860200881958008\n",
      "Inference Time: 0.12067961692810059\n",
      "Inference Time: 0.11468291282653809\n",
      "Inference Time: 0.11269354820251465\n",
      "Inference Time: 0.11768317222595215\n",
      "Inference Time: 0.10671377182006836\n",
      "Inference Time: 0.1346435546875\n",
      "Inference Time: 0.12865400314331055\n",
      "Inference Time: 0.1228327751159668\n",
      "Inference Time: 0.12218213081359863\n",
      "Inference Time: 0.11768293380737305\n",
      "Inference Time: 0.13364386558532715\n",
      "Inference Time: 0.14162063598632812\n",
      "Inference Time: 0.1605682373046875\n",
      "Inference Time: 0.14461016654968262\n",
      "Inference Time: 0.1276562213897705\n",
      "Inference Time: 0.12467193603515625\n",
      "Inference Time: 0.1471421718597412\n",
      "Inference Time: 0.11269044876098633\n",
      "Inference Time: 0.1216745376586914\n",
      "Inference Time: 0.1204071044921875\n",
      "Inference Time: 0.17006134986877441\n",
      "Inference Time: 0.1311640739440918\n",
      "Inference Time: 0.15955567359924316\n",
      "Inference Time: 0.16356158256530762\n",
      "Inference Time: 0.12266993522644043\n",
      "Inference Time: 0.1216742992401123\n",
      "Inference Time: 0.10970401763916016\n",
      "Inference Time: 0.11967682838439941\n",
      "Inference Time: 0.13364052772521973\n",
      "Inference Time: 0.12566232681274414\n",
      "Inference Time: 0.12865519523620605\n",
      "Inference Time: 0.13715648651123047\n",
      "Inference Time: 0.13463735580444336\n",
      "Inference Time: 0.11968016624450684\n",
      "Inference Time: 0.1216742992401123\n",
      "Inference Time: 0.11170077323913574\n",
      "Inference Time: 0.12566423416137695\n",
      "Inference Time: 0.12067770957946777\n",
      "Inference Time: 0.12417888641357422\n",
      "Inference Time: 0.11768078804016113\n",
      "Inference Time: 0.1436138153076172\n",
      "Inference Time: 0.15259265899658203\n",
      "Inference Time: 0.1422102451324463\n",
      "Inference Time: 0.1326456069946289\n",
      "Inference Time: 0.13463902473449707\n",
      "Inference Time: 0.12267017364501953\n",
      "Inference Time: 0.12666058540344238\n",
      "Inference Time: 0.11569023132324219\n",
      "Inference Time: 0.14866876602172852\n",
      "Inference Time: 0.11568832397460938\n",
      "Inference Time: 0.11320614814758301\n",
      "Inference Time: 0.1199042797088623\n",
      "Inference Time: 0.12567830085754395\n",
      "Inference Time: 0.12267112731933594\n",
      "Inference Time: 0.11768555641174316\n",
      "Inference Time: 0.13251543045043945\n",
      "Inference Time: 0.13813996315002441\n",
      "Inference Time: 0.1370840072631836\n",
      "Inference Time: 0.12717437744140625\n",
      "Inference Time: 0.15658187866210938\n",
      "Inference Time: 0.11768555641174316\n",
      "Inference Time: 0.12566399574279785\n",
      "Inference Time: 0.11169743537902832\n",
      "Inference Time: 0.12067627906799316\n",
      "Inference Time: 0.12096977233886719\n",
      "Inference Time: 0.10970807075500488\n",
      "Inference Time: 0.10799980163574219\n",
      "Inference Time: 0.11619949340820312\n",
      "Inference Time: 0.11369538307189941\n",
      "Inference Time: 0.11568975448608398\n",
      "Inference Time: 0.1077113151550293\n",
      "Inference Time: 0.11169958114624023\n",
      "Inference Time: 0.13463807106018066\n",
      "Inference Time: 0.14760494232177734\n",
      "Inference Time: 0.20046305656433105\n",
      "Inference Time: 0.1855020523071289\n",
      "Inference Time: 0.1186819076538086\n",
      "Inference Time: 0.13515233993530273\n",
      "Inference Time: 0.14461398124694824\n",
      "Inference Time: 0.18550634384155273\n",
      "Inference Time: 0.2009727954864502\n",
      "Inference Time: 0.1436171531677246\n",
      "Inference Time: 0.13164710998535156\n",
      "Inference Time: 0.11668634414672852\n",
      "Inference Time: 0.132643461227417\n",
      "Inference Time: 0.1276564598083496\n",
      "Inference Time: 0.11668682098388672\n",
      "Inference Time: 0.10921788215637207\n",
      "Inference Time: 0.1321558952331543\n",
      "Inference Time: 0.1186821460723877\n",
      "Inference Time: 0.11369800567626953\n",
      "Inference Time: 0.11269879341125488\n",
      "Inference Time: 0.11106324195861816\n",
      "Inference Time: 0.12366890907287598\n",
      "Inference Time: 0.11569070816040039\n",
      "Inference Time: 0.11269879341125488\n",
      "Inference Time: 0.12366628646850586\n",
      "Inference Time: 0.12366747856140137\n",
      "Inference Time: 0.11170029640197754\n",
      "Inference Time: 0.10968589782714844\n",
      "Inference Time: 0.11469149589538574\n",
      "Inference Time: 0.10970592498779297\n",
      "Inference Time: 0.12467050552368164\n",
      "Inference Time: 0.10820531845092773\n",
      "Inference Time: 0.11829638481140137\n",
      "Inference Time: 0.11420583724975586\n",
      "Inference Time: 0.11170005798339844\n",
      "Inference Time: 0.1270465850830078\n",
      "Inference Time: 0.1156911849975586\n",
      "Inference Time: 0.12067675590515137\n",
      "Inference Time: 0.11668705940246582\n",
      "Inference Time: 0.12865304946899414\n",
      "Inference Time: 0.11469078063964844\n",
      "Inference Time: 0.11070132255554199\n",
      "Inference Time: 0.12366867065429688\n",
      "Inference Time: 0.1266622543334961\n",
      "Inference Time: 0.12686586380004883\n",
      "Inference Time: 0.12865948677062988\n",
      "Inference Time: 0.12566113471984863\n",
      "Inference Time: 0.14612150192260742\n",
      "Inference Time: 0.14523077011108398\n",
      "Inference Time: 0.12417984008789062\n",
      "Inference Time: 0.12466573715209961\n",
      "Inference Time: 0.11968016624450684\n",
      "Inference Time: 0.12566304206848145\n",
      "Inference Time: 0.11768531799316406\n",
      "Inference Time: 0.1266613006591797\n",
      "Inference Time: 0.12366795539855957\n",
      "Inference Time: 0.12566518783569336\n",
      "Inference Time: 0.11469197273254395\n",
      "Inference Time: 0.11569094657897949\n",
      "Inference Time: 0.10870766639709473\n",
      "Inference Time: 0.11217761039733887\n",
      "Inference Time: 0.11178350448608398\n",
      "Inference Time: 0.10921597480773926\n",
      "Inference Time: 0.11668729782104492\n",
      "Inference Time: 0.11768507957458496\n",
      "Inference Time: 0.11967730522155762\n",
      "Inference Time: 0.11568737030029297\n",
      "Inference Time: 0.11668634414672852\n",
      "Inference Time: 0.11170077323913574\n",
      "Inference Time: 0.11369514465332031\n",
      "Inference Time: 0.12067341804504395\n",
      "Inference Time: 0.11369919776916504\n",
      "Inference Time: 0.1186819076538086\n",
      "Inference Time: 0.11170148849487305\n",
      "Inference Time: 0.12636137008666992\n",
      "Inference Time: 0.11620140075683594\n",
      "Inference Time: 0.11423110961914062\n",
      "Inference Time: 0.10922050476074219\n",
      "Inference Time: 0.10870933532714844\n",
      "Inference Time: 0.12067222595214844\n",
      "Inference Time: 0.12167239189147949\n",
      "Inference Time: 0.11768412590026855\n",
      "Inference Time: 0.10970711708068848\n",
      "Inference Time: 0.12468528747558594\n",
      "Inference Time: 0.1126871109008789\n",
      "Inference Time: 0.11021566390991211\n",
      "Inference Time: 0.11270761489868164\n",
      "Inference Time: 0.1107017993927002\n",
      "Inference Time: 0.13463878631591797\n",
      "Inference Time: 0.10723161697387695\n",
      "Inference Time: 0.11903738975524902\n",
      "Inference Time: 0.10894894599914551\n",
      "Inference Time: 0.11712884902954102\n",
      "Inference Time: 0.12566328048706055\n",
      "Inference Time: 0.11269783973693848\n",
      "Inference Time: 0.1077120304107666\n",
      "Inference Time: 0.11668729782104492\n",
      "Inference Time: 0.12366890907287598\n",
      "Inference Time: 0.11169981956481934\n",
      "Inference Time: 0.11768603324890137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0.12267088890075684\n",
      "Inference Time: 0.1132512092590332\n",
      "Inference Time: 0.12366914749145508\n",
      "Inference Time: 0.11070442199707031\n",
      "Inference Time: 0.11868166923522949\n",
      "Inference Time: 0.11269807815551758\n",
      "Inference Time: 0.12067937850952148\n",
      "Inference Time: 0.10870862007141113\n",
      "Inference Time: 0.11868166923522949\n",
      "Inference Time: 0.11967182159423828\n",
      "Inference Time: 0.10771036148071289\n",
      "Inference Time: 0.12366604804992676\n",
      "Inference Time: 0.1211848258972168\n",
      "Inference Time: 0.11070489883422852\n",
      "Inference Time: 0.10970497131347656\n",
      "Inference Time: 0.1107025146484375\n",
      "Inference Time: 0.12217569351196289\n",
      "Inference Time: 0.1181936264038086\n",
      "Inference Time: 0.11420941352844238\n",
      "Inference Time: 0.10870814323425293\n",
      "Inference Time: 0.12666010856628418\n",
      "Inference Time: 0.10970878601074219\n",
      "Inference Time: 0.12267088890075684\n",
      "Inference Time: 0.10970664024353027\n",
      "Inference Time: 0.10771012306213379\n",
      "Inference Time: 0.12566065788269043\n",
      "Inference Time: 0.12418222427368164\n",
      "Inference Time: 0.10971212387084961\n",
      "Inference Time: 0.11469626426696777\n",
      "Inference Time: 0.11968183517456055\n",
      "Inference Time: 0.11170029640197754\n",
      "Inference Time: 0.1261601448059082\n",
      "Inference Time: 0.1102137565612793\n",
      "Inference Time: 0.10871243476867676\n",
      "Inference Time: 0.13763213157653809\n",
      "Inference Time: 0.11768436431884766\n",
      "Inference Time: 0.11967825889587402\n",
      "Inference Time: 0.28623437881469727\n",
      "Inference Time: 0.13068771362304688\n",
      "Inference Time: 0.13288307189941406\n",
      "Inference Time: 0.13763141632080078\n",
      "Inference Time: 0.1396181583404541\n",
      "Inference Time: 0.12617850303649902\n",
      "Inference Time: 0.14062285423278809\n",
      "Inference Time: 0.1386275291442871\n",
      "Inference Time: 0.17552971839904785\n",
      "Inference Time: 0.11469173431396484\n",
      "Inference Time: 0.12266969680786133\n",
      "Inference Time: 0.14360356330871582\n",
      "Inference Time: 0.12616944313049316\n",
      "Inference Time: 0.129652738571167\n",
      "Inference Time: 0.13264942169189453\n",
      "Inference Time: 0.16057538986206055\n",
      "Inference Time: 0.22243046760559082\n",
      "Inference Time: 0.20046257972717285\n",
      "Inference Time: 0.26329493522644043\n",
      "Inference Time: 0.20844197273254395\n",
      "Inference Time: 0.25829052925109863\n",
      "Inference Time: 0.17804431915283203\n",
      "Inference Time: 0.15957212448120117\n",
      "Inference Time: 0.18469738960266113\n",
      "Inference Time: 0.40606212615966797\n",
      "Inference Time: 0.13364171981811523\n",
      "Inference Time: 0.12765812873840332\n",
      "Inference Time: 0.16755056381225586\n",
      "Inference Time: 0.19141101837158203\n",
      "Inference Time: 0.11568880081176758\n",
      "Inference Time: 0.1575794219970703\n",
      "Inference Time: 0.13406753540039062\n",
      "Inference Time: 0.12716937065124512\n",
      "Inference Time: 0.11368989944458008\n",
      "Inference Time: 0.11369633674621582\n",
      "Inference Time: 0.16256427764892578\n",
      "Inference Time: 0.13962650299072266\n",
      "Inference Time: 0.1416027545928955\n",
      "Inference Time: 0.11768531799316406\n",
      "Inference Time: 0.1356344223022461\n",
      "Inference Time: 0.14438390731811523\n",
      "Inference Time: 0.11768388748168945\n",
      "Inference Time: 0.11568903923034668\n",
      "Inference Time: 0.13051486015319824\n",
      "Inference Time: 0.1157982349395752\n",
      "Inference Time: 0.13364052772521973\n",
      "Inference Time: 0.12267136573791504\n",
      "Inference Time: 0.1356372833251953\n",
      "Inference Time: 0.14162015914916992\n",
      "Inference Time: 0.1246645450592041\n",
      "Inference Time: 0.13663125038146973\n",
      "Inference Time: 0.12816762924194336\n",
      "Inference Time: 0.11968183517456055\n",
      "Inference Time: 0.11768436431884766\n",
      "Inference Time: 0.11269783973693848\n",
      "Inference Time: 0.13224482536315918\n",
      "Inference Time: 0.15111637115478516\n",
      "Inference Time: 0.12666082382202148\n",
      "Inference Time: 0.11967802047729492\n",
      "Inference Time: 0.13164663314819336\n",
      "Inference Time: 0.1356339454650879\n",
      "Inference Time: 0.12466621398925781\n",
      "Inference Time: 0.11768341064453125\n",
      "Inference Time: 0.11121225357055664\n",
      "Inference Time: 0.13615131378173828\n",
      "Inference Time: 0.10722160339355469\n",
      "Inference Time: 0.10552573204040527\n",
      "Inference Time: 0.10801362991333008\n",
      "Inference Time: 0.115692138671875\n",
      "Inference Time: 0.11768436431884766\n",
      "Inference Time: 0.11356377601623535\n",
      "Inference Time: 0.12067437171936035\n",
      "Inference Time: 0.12367010116577148\n",
      "Inference Time: 0.11469221115112305\n",
      "Inference Time: 0.12865996360778809\n",
      "Inference Time: 0.1715385913848877\n",
      "Inference Time: 0.1515965461730957\n",
      "Inference Time: 0.11968660354614258\n",
      "Inference Time: 0.12169289588928223\n",
      "Inference Time: 0.13062000274658203\n",
      "Inference Time: 0.1257009506225586\n",
      "Inference Time: 0.1284327507019043\n",
      "Inference Time: 0.1241762638092041\n",
      "Inference Time: 0.11121487617492676\n",
      "Inference Time: 0.12816810607910156\n",
      "Inference Time: 0.14162063598632812\n",
      "Inference Time: 0.12466287612915039\n",
      "Inference Time: 0.13164782524108887\n",
      "Inference Time: 0.13463592529296875\n",
      "Inference Time: 0.14162087440490723\n",
      "Inference Time: 0.1371452808380127\n",
      "Inference Time: 0.13509631156921387\n",
      "Inference Time: 0.13064861297607422\n",
      "Inference Time: 0.13763070106506348\n",
      "Inference Time: 0.13862824440002441\n",
      "Inference Time: 0.13463950157165527\n",
      "Inference Time: 0.13862991333007812\n",
      "Inference Time: 0.1326432228088379\n",
      "Inference Time: 0.14760327339172363\n",
      "Inference Time: 0.1635606288909912\n",
      "Inference Time: 0.13364195823669434\n",
      "Inference Time: 0.13714218139648438\n",
      "Inference Time: 0.12666058540344238\n",
      "Inference Time: 0.11868476867675781\n",
      "Inference Time: 0.13065314292907715\n",
      "Inference Time: 0.13563060760498047\n",
      "Inference Time: 0.1331644058227539\n",
      "Inference Time: 0.12466597557067871\n",
      "Inference Time: 0.12067413330078125\n",
      "Inference Time: 0.13564109802246094\n",
      "Inference Time: 0.12366843223571777\n",
      "Inference Time: 0.11568951606750488\n",
      "Inference Time: 0.118682861328125\n",
      "Inference Time: 0.14014005661010742\n",
      "Inference Time: 0.14327406883239746\n",
      "Inference Time: 0.12865328788757324\n",
      "Inference Time: 0.12367677688598633\n",
      "Inference Time: 0.168060302734375\n",
      "Inference Time: 0.16555523872375488\n",
      "Inference Time: 0.13463664054870605\n",
      "Inference Time: 0.12566399574279785\n",
      "Inference Time: 0.12267088890075684\n",
      "Inference Time: 0.12267208099365234\n",
      "Inference Time: 0.1216740608215332\n",
      "Inference Time: 0.11919522285461426\n",
      "Inference Time: 0.11520171165466309\n",
      "Inference Time: 0.11968469619750977\n",
      "Inference Time: 0.144622802734375\n",
      "Inference Time: 0.12865400314331055\n",
      "Inference Time: 0.12973356246948242\n",
      "Inference Time: 0.13514971733093262\n",
      "Inference Time: 0.12765908241271973\n",
      "Inference Time: 0.1356358528137207\n",
      "Inference Time: 0.10870575904846191\n",
      "Inference Time: 0.11170077323913574\n",
      "Inference Time: 0.1515944004058838\n",
      "Inference Time: 0.16854071617126465\n",
      "Inference Time: 0.1296553611755371\n",
      "Inference Time: 0.1934809684753418\n",
      "Inference Time: 0.13164782524108887\n",
      "Inference Time: 0.12418174743652344\n",
      "Inference Time: 0.12418007850646973\n",
      "Inference Time: 0.13563752174377441\n",
      "Inference Time: 0.14162111282348633\n",
      "Inference Time: 0.13164567947387695\n",
      "Inference Time: 0.13564229011535645\n",
      "Inference Time: 0.14760470390319824\n",
      "Inference Time: 0.11469244956970215\n",
      "Inference Time: 0.11671137809753418\n",
      "Inference Time: 0.11075925827026367\n",
      "Inference Time: 0.12167501449584961\n",
      "Inference Time: 0.1136941909790039\n",
      "Inference Time: 0.12068343162536621\n",
      "Inference Time: 0.11070632934570312\n",
      "Inference Time: 0.12218546867370605\n",
      "Inference Time: 0.12466597557067871\n",
      "Inference Time: 0.1156914234161377\n",
      "Inference Time: 0.1266617774963379\n",
      "Inference Time: 0.11668562889099121\n",
      "Inference Time: 0.13164639472961426\n",
      "Inference Time: 0.13463735580444336\n",
      "Inference Time: 0.2029709815979004\n",
      "Inference Time: 0.15853476524353027\n",
      "Inference Time: 0.12267780303955078\n",
      "Inference Time: 0.1152040958404541\n",
      "Inference Time: 0.12616634368896484\n",
      "Inference Time: 0.1406233310699463\n",
      "Inference Time: 0.12067532539367676\n",
      "Inference Time: 0.18350791931152344\n",
      "Inference Time: 0.1495990753173828\n",
      "Inference Time: 0.12067675590515137\n",
      "Inference Time: 0.1296522617340088\n",
      "Inference Time: 0.1206810474395752\n",
      "Inference Time: 0.12849020957946777\n",
      "Inference Time: 0.1276535987854004\n",
      "Inference Time: 0.11967754364013672\n",
      "Inference Time: 0.12765908241271973\n",
      "Inference Time: 0.12545228004455566\n",
      "Inference Time: 0.11221194267272949\n",
      "Inference Time: 0.11420392990112305\n",
      "Inference Time: 0.12267088890075684\n",
      "Inference Time: 0.12765789031982422\n",
      "Inference Time: 0.11269760131835938\n",
      "Inference Time: 0.11568808555603027\n",
      "Inference Time: 0.12765836715698242\n",
      "Inference Time: 0.14561104774475098\n",
      "Inference Time: 0.13814306259155273\n",
      "Inference Time: 0.1237494945526123\n",
      "Inference Time: 0.11719727516174316\n",
      "Inference Time: 0.1206817626953125\n",
      "Inference Time: 0.12365937232971191\n",
      "Inference Time: 0.10571551322937012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0.12167477607727051\n",
      "Inference Time: 0.11192846298217773\n",
      "Inference Time: 0.11768293380737305\n",
      "Inference Time: 0.10970592498779297\n",
      "Inference Time: 0.12666058540344238\n",
      "Inference Time: 0.14162182807922363\n",
      "Inference Time: 0.19447731971740723\n",
      "Inference Time: 0.1356363296508789\n",
      "Inference Time: 0.157578706741333\n",
      "Inference Time: 0.11016130447387695\n",
      "Inference Time: 0.12665772438049316\n",
      "Inference Time: 0.12067651748657227\n",
      "Inference Time: 0.1301875114440918\n",
      "Inference Time: 0.12267112731933594\n",
      "Inference Time: 0.124664306640625\n",
      "Inference Time: 0.12167596817016602\n",
      "Inference Time: 0.1515960693359375\n",
      "Inference Time: 0.11668539047241211\n",
      "Inference Time: 0.11668634414672852\n",
      "Inference Time: 0.1107032299041748\n",
      "Inference Time: 0.10970592498779297\n",
      "Inference Time: 0.12067651748657227\n",
      "Inference Time: 0.1107034683227539\n",
      "Inference Time: 0.11322593688964844\n",
      "Inference Time: 0.12069201469421387\n",
      "Inference Time: 0.10821938514709473\n",
      "Inference Time: 0.12067532539367676\n",
      "Inference Time: 0.11170029640197754\n",
      "Inference Time: 0.11269807815551758\n",
      "Inference Time: 0.11070394515991211\n",
      "Inference Time: 0.12366914749145508\n",
      "Inference Time: 0.11070132255554199\n",
      "Inference Time: 0.13164591789245605\n",
      "Inference Time: 0.11768388748168945\n",
      "Inference Time: 0.1083979606628418\n",
      "Inference Time: 0.12665605545043945\n",
      "Inference Time: 0.1306161880493164\n",
      "Inference Time: 0.1241767406463623\n",
      "Inference Time: 0.11784482002258301\n",
      "Inference Time: 0.12167525291442871\n",
      "Inference Time: 0.13164758682250977\n",
      "Inference Time: 0.1216738224029541\n",
      "Inference Time: 0.12566232681274414\n",
      "Inference Time: 0.12466812133789062\n",
      "Inference Time: 0.1136929988861084\n",
      "Inference Time: 0.11668634414672852\n",
      "Inference Time: 0.11269569396972656\n",
      "Inference Time: 0.10999083518981934\n",
      "Inference Time: 0.13364219665527344\n",
      "Inference Time: 0.12466573715209961\n",
      "Inference Time: 0.10912179946899414\n",
      "Inference Time: 0.10722732543945312\n",
      "Inference Time: 0.12218594551086426\n",
      "Inference Time: 0.11070370674133301\n",
      "Inference Time: 0.12367129325866699\n",
      "Inference Time: 0.11170172691345215\n",
      "Inference Time: 0.11469292640686035\n",
      "Inference Time: 0.12865352630615234\n",
      "Inference Time: 0.11668872833251953\n",
      "Inference Time: 0.11868095397949219\n",
      "Inference Time: 0.11320877075195312\n",
      "Inference Time: 0.12720775604248047\n",
      "Inference Time: 0.11968278884887695\n",
      "Inference Time: 0.11568808555603027\n",
      "Inference Time: 0.11607885360717773\n",
      "Inference Time: 0.11269664764404297\n",
      "Inference Time: 0.12566375732421875\n",
      "Inference Time: 0.1186826229095459\n",
      "Inference Time: 0.11169958114624023\n",
      "Inference Time: 0.10970544815063477\n",
      "Inference Time: 0.12267088890075684\n",
      "Inference Time: 0.11170196533203125\n",
      "Inference Time: 0.12067437171936035\n",
      "Inference Time: 0.11568713188171387\n",
      "Inference Time: 0.11968111991882324\n",
      "Inference Time: 0.12566304206848145\n",
      "Inference Time: 0.11620020866394043\n",
      "Inference Time: 0.11420416831970215\n",
      "Inference Time: 0.1107177734375\n",
      "Inference Time: 0.12366843223571777\n",
      "Inference Time: 0.1216731071472168\n",
      "Inference Time: 0.11768579483032227\n",
      "Inference Time: 0.13463950157165527\n",
      "Inference Time: 0.1326432228088379\n",
      "Inference Time: 0.14660334587097168\n",
      "Inference Time: 0.1466083526611328\n",
      "Inference Time: 0.15059900283813477\n",
      "Inference Time: 0.1896369457244873\n",
      "Inference Time: 0.14013457298278809\n",
      "Inference Time: 0.12418222427368164\n",
      "Inference Time: 0.11170053482055664\n",
      "Inference Time: 0.12466621398925781\n",
      "Inference Time: 0.12267160415649414\n",
      "Inference Time: 0.11568832397460938\n",
      "Inference Time: 0.20844173431396484\n",
      "Inference Time: 0.14062261581420898\n",
      "Inference Time: 0.15011119842529297\n",
      "Inference Time: 0.12865495681762695\n",
      "Inference Time: 0.12566328048706055\n",
      "Inference Time: 0.12617921829223633\n",
      "Inference Time: 0.11702108383178711\n",
      "Inference Time: 0.13117527961730957\n",
      "Inference Time: 0.16458868980407715\n",
      "Inference Time: 0.1356346607208252\n",
      "Inference Time: 0.20844197273254395\n",
      "Inference Time: 0.11668729782104492\n",
      "Inference Time: 0.14162135124206543\n",
      "Inference Time: 0.1216738224029541\n",
      "Inference Time: 0.12917780876159668\n",
      "Inference Time: 0.13763141632080078\n",
      "Inference Time: 0.13364338874816895\n",
      "Inference Time: 0.12566304206848145\n",
      "Inference Time: 0.12319040298461914\n",
      "Inference Time: 0.11619162559509277\n",
      "Inference Time: 0.12267184257507324\n",
      "Inference Time: 0.12266969680786133\n",
      "Inference Time: 0.11070370674133301\n",
      "Inference Time: 0.11868143081665039\n",
      "Inference Time: 0.11568784713745117\n",
      "Inference Time: 0.11369442939758301\n",
      "Inference Time: 0.11668920516967773\n",
      "Inference Time: 0.12102222442626953\n",
      "Inference Time: 0.12965059280395508\n",
      "Inference Time: 0.11768579483032227\n",
      "Inference Time: 0.11568856239318848\n",
      "Inference Time: 0.13216280937194824\n",
      "Inference Time: 0.13714218139648438\n",
      "Inference Time: 0.12566328048706055\n",
      "Inference Time: 0.1216731071472168\n",
      "Inference Time: 0.11369538307189941\n",
      "Inference Time: 0.16655206680297852\n",
      "Inference Time: 0.12566304206848145\n",
      "Inference Time: 0.12566184997558594\n",
      "Inference Time: 0.11768412590026855\n",
      "Inference Time: 0.1436173915863037\n",
      "Inference Time: 0.12865734100341797\n",
      "Inference Time: 0.2870490550994873\n",
      "Inference Time: 0.26144838333129883\n",
      "Inference Time: 0.16455888748168945\n",
      "Inference Time: 0.22240447998046875\n",
      "Inference Time: 0.1625669002532959\n",
      "Inference Time: 0.1366283893585205\n",
      "Inference Time: 0.1077115535736084\n",
      "Inference Time: 0.14741945266723633\n",
      "Inference Time: 0.14063191413879395\n",
      "Inference Time: 0.20744609832763672\n",
      "Inference Time: 0.12698841094970703\n",
      "Inference Time: 0.12067627906799316\n",
      "Inference Time: 0.1386258602142334\n",
      "Inference Time: 0.12965106964111328\n",
      "Inference Time: 0.12566351890563965\n",
      "Inference Time: 0.11469364166259766\n",
      "Inference Time: 0.1356368064880371\n",
      "Inference Time: 0.18051767349243164\n",
      "Inference Time: 0.16356253623962402\n",
      "Inference Time: 0.1216728687286377\n",
      "Inference Time: 0.11945700645446777\n",
      "Inference Time: 0.12318038940429688\n",
      "Inference Time: 0.12566184997558594\n",
      "Inference Time: 0.13663387298583984\n",
      "Inference Time: 0.14560961723327637\n",
      "Inference Time: 0.12366700172424316\n",
      "Inference Time: 0.12765789031982422\n",
      "Inference Time: 0.1296525001525879\n",
      "Inference Time: 0.13367199897766113\n",
      "Inference Time: 0.12965154647827148\n",
      "Inference Time: 0.12658953666687012\n",
      "Inference Time: 0.12366843223571777\n",
      "Inference Time: 0.14461326599121094\n",
      "Inference Time: 0.12617206573486328\n",
      "Inference Time: 0.1198740005493164\n",
      "Inference Time: 0.11023974418640137\n",
      "Inference Time: 0.10970735549926758\n",
      "Inference Time: 0.1216740608215332\n",
      "Inference Time: 0.10870862007141113\n",
      "Inference Time: 0.12466788291931152\n",
      "Inference Time: 0.1246652603149414\n",
      "Inference Time: 0.12167501449584961\n",
      "Inference Time: 0.10870790481567383\n",
      "Inference Time: 0.1107017993927002\n",
      "Inference Time: 0.11070489883422852\n",
      "Inference Time: 0.11869239807128906\n",
      "Inference Time: 0.1105961799621582\n",
      "Inference Time: 0.11223173141479492\n",
      "Inference Time: 0.1790328025817871\n",
      "Inference Time: 0.12366890907287598\n",
      "Inference Time: 0.1685495376586914\n",
      "Inference Time: 0.1376323699951172\n",
      "Inference Time: 0.13959431648254395\n",
      "Inference Time: 0.12665987014770508\n",
      "Inference Time: 0.11720013618469238\n",
      "Inference Time: 0.14462637901306152\n",
      "Inference Time: 0.13164734840393066\n",
      "Inference Time: 0.11093688011169434\n",
      "Inference Time: 0.14339709281921387\n",
      "Inference Time: 0.1341569423675537\n",
      "Inference Time: 0.12566256523132324\n",
      "Inference Time: 0.11070489883422852\n",
      "Inference Time: 0.1326441764831543\n",
      "Inference Time: 0.11968231201171875\n",
      "Inference Time: 0.12067580223083496\n",
      "Inference Time: 0.11172246932983398\n",
      "Inference Time: 0.12517809867858887\n",
      "Inference Time: 0.10822010040283203\n",
      "Inference Time: 0.1186823844909668\n",
      "Inference Time: 0.12865948677062988\n",
      "Inference Time: 0.12865686416625977\n",
      "Inference Time: 0.12717103958129883\n",
      "Inference Time: 0.13663530349731445\n",
      "Inference Time: 0.1466062068939209\n",
      "Inference Time: 0.15159368515014648\n",
      "Inference Time: 0.11768627166748047\n",
      "Inference Time: 0.11269783973693848\n",
      "Inference Time: 0.11269617080688477\n",
      "Inference Time: 0.1346418857574463\n",
      "Inference Time: 0.12517762184143066\n",
      "Inference Time: 0.12367534637451172\n",
      "Inference Time: 0.12566208839416504\n",
      "Inference Time: 0.1266627311706543\n",
      "Inference Time: 0.12816762924194336\n",
      "Inference Time: 0.12369918823242188\n",
      "Inference Time: 0.14711880683898926\n",
      "Inference Time: 0.14162111282348633\n",
      "Inference Time: 0.12566089630126953\n",
      "Inference Time: 0.12466692924499512\n",
      "Inference Time: 0.1560978889465332\n",
      "Inference Time: 0.11269783973693848\n",
      "Inference Time: 0.12566328048706055\n",
      "Inference Time: 0.12566399574279785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0.1575760841369629\n",
      "Inference Time: 0.13663554191589355\n",
      "Inference Time: 0.12127876281738281\n",
      "Inference Time: 0.12842726707458496\n",
      "Inference Time: 0.13814210891723633\n",
      "Inference Time: 0.12865591049194336\n",
      "Inference Time: 0.11768436431884766\n",
      "Inference Time: 0.11668896675109863\n",
      "Inference Time: 0.18451142311096191\n",
      "Inference Time: 0.1356348991394043\n",
      "Inference Time: 0.11768221855163574\n",
      "Inference Time: 0.1261746883392334\n",
      "Inference Time: 0.1266627311706543\n",
      "Inference Time: 0.13663578033447266\n",
      "Inference Time: 0.11784243583679199\n",
      "Inference Time: 0.12568330764770508\n",
      "Inference Time: 0.14712071418762207\n",
      "Inference Time: 0.12365865707397461\n",
      "Inference Time: 0.1296525001525879\n",
      "Inference Time: 0.1376338005065918\n",
      "Inference Time: 0.17846417427062988\n",
      "Inference Time: 0.1296532154083252\n",
      "Inference Time: 0.13463950157165527\n",
      "Inference Time: 0.14861226081848145\n",
      "Inference Time: 0.12166953086853027\n",
      "Inference Time: 0.13065481185913086\n",
      "Inference Time: 0.14013385772705078\n",
      "Inference Time: 0.14760375022888184\n",
      "Inference Time: 0.16356301307678223\n",
      "Inference Time: 0.1266622543334961\n",
      "Inference Time: 0.18550586700439453\n",
      "Inference Time: 0.14760518074035645\n",
      "Inference Time: 0.1186819076538086\n",
      "Inference Time: 0.12916922569274902\n",
      "Inference Time: 0.16987299919128418\n",
      "Inference Time: 0.17553997039794922\n",
      "Inference Time: 0.2219257354736328\n",
      "Inference Time: 0.3515634536743164\n",
      "Inference Time: 0.2184145450592041\n",
      "Inference Time: 0.2962069511413574\n",
      "Inference Time: 0.23537087440490723\n",
      "Inference Time: 0.20496177673339844\n",
      "Inference Time: 0.15059399604797363\n",
      "Inference Time: 0.14534258842468262\n",
      "Inference Time: 0.13164949417114258\n",
      "Inference Time: 0.13463830947875977\n",
      "Inference Time: 0.12865662574768066\n",
      "Inference Time: 0.1296534538269043\n",
      "Inference Time: 0.1296534538269043\n",
      "Inference Time: 0.15159392356872559\n",
      "Inference Time: 0.12267351150512695\n",
      "Inference Time: 0.12666106224060059\n",
      "Inference Time: 0.1316545009613037\n",
      "Inference Time: 0.13962745666503906\n",
      "Inference Time: 0.12067031860351562\n",
      "Inference Time: 0.13315534591674805\n",
      "Inference Time: 0.1296536922454834\n",
      "Inference Time: 0.15754151344299316\n",
      "Inference Time: 0.11768531799316406\n",
      "Inference Time: 0.12566328048706055\n",
      "Inference Time: 0.12067484855651855\n",
      "Inference Time: 0.1466073989868164\n",
      "Inference Time: 0.12916350364685059\n",
      "Inference Time: 0.14313030242919922\n",
      "Inference Time: 0.12167167663574219\n",
      "Inference Time: 0.1406240463256836\n",
      "Inference Time: 0.11722993850708008\n",
      "Inference Time: 0.23836302757263184\n",
      "Inference Time: 0.13164663314819336\n",
      "Inference Time: 0.1466083526611328\n",
      "Inference Time: 0.12466573715209961\n",
      "Inference Time: 0.13164424896240234\n",
      "Inference Time: 0.13164806365966797\n",
      "Inference Time: 0.14712285995483398\n",
      "Inference Time: 0.14960479736328125\n",
      "Inference Time: 0.1356337070465088\n",
      "Inference Time: 0.13564205169677734\n",
      "Inference Time: 0.12469291687011719\n",
      "Inference Time: 0.12518024444580078\n",
      "Inference Time: 0.12765979766845703\n",
      "Inference Time: 0.13463807106018066\n",
      "Inference Time: 0.12067580223083496\n",
      "Inference Time: 0.13065028190612793\n",
      "Inference Time: 0.47679901123046875\n",
      "Inference Time: 0.33121609687805176\n",
      "Inference Time: 0.3681681156158447\n",
      "Inference Time: 0.39666748046875\n",
      "Inference Time: 0.15558362007141113\n",
      "Inference Time: 0.1406238079071045\n",
      "Inference Time: 0.15059709548950195\n",
      "Inference Time: 0.2009742259979248\n",
      "Inference Time: 0.1765279769897461\n",
      "Inference Time: 0.16952991485595703\n",
      "Inference Time: 0.12668347358703613\n",
      "Inference Time: 0.18703079223632812\n",
      "Inference Time: 0.19547438621520996\n",
      "Inference Time: 0.13762331008911133\n",
      "Inference Time: 0.13364005088806152\n",
      "Inference Time: 0.3311309814453125\n",
      "Inference Time: 0.24286866188049316\n",
      "Inference Time: 0.24640297889709473\n",
      "Inference Time: 0.2812826633453369\n",
      "Inference Time: 0.21194720268249512\n",
      "Inference Time: 0.1391444206237793\n",
      "Inference Time: 0.14560985565185547\n",
      "Inference Time: 0.15858030319213867\n",
      "Inference Time: 0.13064789772033691\n",
      "Inference Time: 0.13364148139953613\n",
      "Inference Time: 0.154587984085083\n",
      "Inference Time: 0.12418723106384277\n",
      "Inference Time: 0.17504453659057617\n",
      "Inference Time: 0.14261841773986816\n",
      "Inference Time: 0.1545848846435547\n",
      "Inference Time: 0.13116002082824707\n",
      "Inference Time: 0.1306769847869873\n",
      "Inference Time: 0.3257637023925781\n",
      "Inference Time: 0.25731754302978516\n",
      "Inference Time: 0.2263939380645752\n",
      "Inference Time: 0.20842933654785156\n",
      "Inference Time: 0.19946527481079102\n",
      "Inference Time: 0.1835165023803711\n",
      "Inference Time: 0.13764691352844238\n",
      "Inference Time: 0.14459514617919922\n",
      "Inference Time: 0.13566350936889648\n",
      "Inference Time: 0.1371443271636963\n",
      "Inference Time: 0.13663554191589355\n",
      "Inference Time: 0.12865495681762695\n",
      "Inference Time: 0.13564229011535645\n",
      "Inference Time: 0.14261889457702637\n",
      "Inference Time: 0.15957403182983398\n",
      "Inference Time: 0.1575789451599121\n",
      "Inference Time: 0.13065004348754883\n",
      "Inference Time: 0.13762998580932617\n",
      "Inference Time: 0.12287712097167969\n",
      "Inference Time: 0.12778830528259277\n",
      "Inference Time: 0.13364458084106445\n",
      "Inference Time: 0.12167239189147949\n",
      "Inference Time: 0.12466621398925781\n",
      "Inference Time: 0.12366867065429688\n",
      "Inference Time: 0.11868047714233398\n",
      "Inference Time: 0.13663482666015625\n",
      "Inference Time: 0.12865591049194336\n",
      "Inference Time: 0.15510082244873047\n",
      "Inference Time: 0.15857625007629395\n",
      "Inference Time: 0.12167620658874512\n",
      "Inference Time: 0.1351640224456787\n",
      "Inference Time: 0.12717127799987793\n",
      "Inference Time: 0.14812374114990234\n",
      "Inference Time: 0.1291661262512207\n",
      "Inference Time: 0.12666082382202148\n",
      "Inference Time: 0.13464045524597168\n",
      "Inference Time: 0.16057181358337402\n",
      "Inference Time: 0.12566041946411133\n",
      "Inference Time: 0.12865638732910156\n",
      "Inference Time: 0.13116002082824707\n",
      "Inference Time: 0.13463878631591797\n",
      "Inference Time: 0.12467622756958008\n",
      "Inference Time: 0.13463950157165527\n",
      "Inference Time: 0.12765812873840332\n",
      "Inference Time: 0.13264226913452148\n",
      "Inference Time: 0.11469078063964844\n",
      "Inference Time: 0.13065123558044434\n",
      "Inference Time: 0.11568951606750488\n",
      "Inference Time: 0.13065028190612793\n",
      "Inference Time: 0.12650394439697266\n",
      "Inference Time: 0.14711904525756836\n",
      "Inference Time: 0.12965154647827148\n",
      "Inference Time: 0.11868095397949219\n",
      "Inference Time: 0.13463878631591797\n",
      "Inference Time: 0.12284731864929199\n",
      "Inference Time: 0.1261742115020752\n",
      "Inference Time: 0.124664306640625\n",
      "Inference Time: 0.12665963172912598\n",
      "Inference Time: 0.15358901023864746\n",
      "Inference Time: 0.1276569366455078\n",
      "Inference Time: 0.14760494232177734\n",
      "Inference Time: 0.1650679111480713\n",
      "Inference Time: 0.13814043998718262\n",
      "Inference Time: 0.15558195114135742\n",
      "Inference Time: 0.18650174140930176\n",
      "Inference Time: 0.21545076370239258\n",
      "Inference Time: 0.15558290481567383\n",
      "Inference Time: 0.16457080841064453\n",
      "Inference Time: 0.15558218955993652\n",
      "Inference Time: 0.18848967552185059\n",
      "Inference Time: 0.16954445838928223\n",
      "Inference Time: 0.1414639949798584\n",
      "Inference Time: 0.1306469440460205\n",
      "Inference Time: 0.11269950866699219\n",
      "Inference Time: 0.1265091896057129\n",
      "Inference Time: 0.2195262908935547\n",
      "Inference Time: 0.22239041328430176\n",
      "Inference Time: 0.13364338874816895\n",
      "Inference Time: 0.14062952995300293\n",
      "Inference Time: 0.2283937931060791\n",
      "Inference Time: 0.12067580223083496\n",
      "Inference Time: 0.15258574485778809\n",
      "Inference Time: 0.15259146690368652\n",
      "Inference Time: 0.13446617126464844\n",
      "Inference Time: 0.13814234733581543\n",
      "Inference Time: 0.1186833381652832\n",
      "Inference Time: 0.12865424156188965\n",
      "Inference Time: 0.12366986274719238\n",
      "Inference Time: 0.12566661834716797\n",
      "Inference Time: 0.11468982696533203\n",
      "Inference Time: 0.12366795539855957\n",
      "Inference Time: 0.1401355266571045\n",
      "Inference Time: 0.1281719207763672\n",
      "Inference Time: 0.11824226379394531\n",
      "Inference Time: 0.11169981956481934\n",
      "Inference Time: 0.14461183547973633\n",
      "Inference Time: 0.13190340995788574\n",
      "Inference Time: 0.12244319915771484\n",
      "Inference Time: 0.13116741180419922\n",
      "Inference Time: 0.12067508697509766\n",
      "Inference Time: 0.10970640182495117\n",
      "Inference Time: 0.11469078063964844\n",
      "Inference Time: 0.10970497131347656\n",
      "Inference Time: 0.11568975448608398\n",
      "Inference Time: 0.1545860767364502\n",
      "Inference Time: 0.13115930557250977\n",
      "Inference Time: 0.12366843223571777\n",
      "Inference Time: 0.11668777465820312\n",
      "Inference Time: 0.1406235694885254\n",
      "Inference Time: 0.13116216659545898\n",
      "Inference Time: 0.11221146583557129\n",
      "Inference Time: 0.112213134765625\n",
      "Inference Time: 0.12618756294250488\n",
      "Inference Time: 0.11768174171447754\n",
      "Inference Time: 0.1216742992401123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0.11169981956481934\n",
      "Inference Time: 0.1186826229095459\n",
      "Inference Time: 0.11768841743469238\n",
      "Inference Time: 0.11569023132324219\n",
      "Inference Time: 0.11919236183166504\n",
      "Inference Time: 0.11868762969970703\n",
      "Inference Time: 0.12566351890563965\n",
      "Inference Time: 0.11967802047729492\n",
      "Inference Time: 0.11001944541931152\n",
      "Inference Time: 0.1118006706237793\n",
      "Inference Time: 0.12135124206542969\n",
      "Inference Time: 0.11038064956665039\n",
      "Inference Time: 0.11469149589538574\n",
      "Inference Time: 0.12189221382141113\n",
      "Inference Time: 0.11321377754211426\n",
      "Inference Time: 0.13343596458435059\n",
      "Inference Time: 0.12218379974365234\n",
      "Inference Time: 0.12865495681762695\n",
      "Inference Time: 0.13164710998535156\n",
      "Inference Time: 0.13463997840881348\n",
      "Inference Time: 0.13464021682739258\n",
      "Inference Time: 0.1406240463256836\n",
      "Inference Time: 0.12067627906799316\n",
      "Inference Time: 0.12865447998046875\n",
      "Inference Time: 0.11569499969482422\n",
      "Inference Time: 0.12366795539855957\n",
      "Inference Time: 0.10970520973205566\n",
      "Inference Time: 0.10921692848205566\n",
      "Inference Time: 0.1152029037475586\n",
      "Inference Time: 0.1216733455657959\n",
      "Inference Time: 0.14162278175354004\n",
      "Inference Time: 0.13763046264648438\n",
      "Inference Time: 0.1436161994934082\n",
      "Inference Time: 0.14062190055847168\n",
      "Inference Time: 0.13962650299072266\n",
      "Inference Time: 0.1471254825592041\n",
      "Inference Time: 0.1495974063873291\n",
      "Inference Time: 0.14361286163330078\n",
      "Inference Time: 0.1401364803314209\n",
      "Inference Time: 0.13516497611999512\n",
      "Inference Time: 0.11269640922546387\n",
      "Inference Time: 0.11668586730957031\n",
      "Inference Time: 0.12267184257507324\n",
      "Inference Time: 0.12865686416625977\n",
      "Inference Time: 0.15857148170471191\n",
      "Inference Time: 0.13364052772521973\n",
      "Inference Time: 0.1685488224029541\n",
      "Inference Time: 0.1356370449066162\n",
      "Inference Time: 0.13274550437927246\n",
      "Inference Time: 0.1511085033416748\n",
      "Inference Time: 0.17756319046020508\n",
      "Inference Time: 0.218414306640625\n",
      "Inference Time: 0.2812464237213135\n",
      "Inference Time: 0.1605689525604248\n",
      "Inference Time: 0.17752623558044434\n",
      "Inference Time: 0.31182098388671875\n",
      "Inference Time: 0.3186638355255127\n",
      "Inference Time: 0.17885088920593262\n",
      "Inference Time: 0.20303559303283691\n",
      "Inference Time: 0.18450522422790527\n",
      "Inference Time: 0.1436164379119873\n",
      "Inference Time: 0.15259122848510742\n",
      "Inference Time: 0.154585599899292\n",
      "Inference Time: 0.13663482666015625\n",
      "Inference Time: 0.19348883628845215\n",
      "Inference Time: 0.19747018814086914\n",
      "Inference Time: 0.16150689125061035\n",
      "Inference Time: 0.13328862190246582\n",
      "Inference Time: 0.13863039016723633\n",
      "Inference Time: 0.26628708839416504\n",
      "Inference Time: 0.20845508575439453\n",
      "Inference Time: 0.15857529640197754\n",
      "Inference Time: 0.14461517333984375\n",
      "Inference Time: 0.1426229476928711\n",
      "Inference Time: 0.12466645240783691\n",
      "Inference Time: 0.1276564598083496\n",
      "Inference Time: 0.12717032432556152\n",
      "Inference Time: 0.1315019130706787\n",
      "Inference Time: 0.12517499923706055\n",
      "Inference Time: 0.11568999290466309\n",
      "Inference Time: 0.11668729782104492\n",
      "Inference Time: 0.11170125007629395\n",
      "Inference Time: 0.11170077323913574\n",
      "Inference Time: 0.10771298408508301\n",
      "Inference Time: 0.10770916938781738\n",
      "Inference Time: 0.12366771697998047\n",
      "Inference Time: 0.10771322250366211\n",
      "Inference Time: 0.11203503608703613\n",
      "Inference Time: 0.11270284652709961\n",
      "Inference Time: 0.13663458824157715\n",
      "Inference Time: 0.13463902473449707\n",
      "Inference Time: 0.14443039894104004\n",
      "Inference Time: 0.12916994094848633\n",
      "Inference Time: 0.1326441764831543\n",
      "Inference Time: 0.12766265869140625\n",
      "Inference Time: 0.12666010856628418\n",
      "Inference Time: 0.1436159610748291\n",
      "Inference Time: 0.1466078758239746\n",
      "Inference Time: 0.13463997840881348\n",
      "Inference Time: 0.12118649482727051\n",
      "Inference Time: 0.11170816421508789\n",
      "Inference Time: 0.14063048362731934\n",
      "Inference Time: 0.11668777465820312\n",
      "Inference Time: 0.1351485252380371\n",
      "Inference Time: 0.13364076614379883\n",
      "Inference Time: 0.12965178489685059\n",
      "Inference Time: 0.12367010116577148\n",
      "Inference Time: 0.12865447998046875\n",
      "Inference Time: 0.12765765190124512\n",
      "Inference Time: 0.13863086700439453\n",
      "Inference Time: 0.1236734390258789\n",
      "Inference Time: 0.14711523056030273\n",
      "Inference Time: 0.12666797637939453\n",
      "Inference Time: 0.12566184997558594\n",
      "Inference Time: 0.13094282150268555\n",
      "Inference Time: 0.12518000602722168\n",
      "Inference Time: 0.13314294815063477\n",
      "Inference Time: 0.12967777252197266\n",
      "Inference Time: 0.11469507217407227\n",
      "Inference Time: 0.12167572975158691\n",
      "Inference Time: 0.12366771697998047\n",
      "Inference Time: 0.12267065048217773\n",
      "Inference Time: 0.124664306640625\n",
      "Inference Time: 0.12366700172424316\n",
      "Inference Time: 0.1356353759765625\n",
      "Inference Time: 0.1356358528137207\n",
      "Inference Time: 0.12864255905151367\n",
      "Inference Time: 0.13940691947937012\n",
      "Inference Time: 0.14113235473632812\n",
      "Inference Time: 0.1201930046081543\n",
      "Inference Time: 0.11920785903930664\n",
      "Inference Time: 0.12167239189147949\n",
      "Inference Time: 0.12267231941223145\n",
      "Inference Time: 0.1376330852508545\n",
      "Inference Time: 0.12665891647338867\n",
      "Inference Time: 0.11967706680297852\n",
      "Inference Time: 0.13364243507385254\n",
      "Inference Time: 0.11719655990600586\n",
      "Inference Time: 0.11288309097290039\n",
      "Inference Time: 0.11470532417297363\n",
      "Inference Time: 0.10870647430419922\n",
      "Inference Time: 0.1326451301574707\n",
      "Inference Time: 0.11620235443115234\n",
      "Inference Time: 0.1311628818511963\n",
      "Inference Time: 0.11021065711975098\n",
      "Inference Time: 0.13663220405578613\n",
      "Inference Time: 0.12366890907287598\n",
      "Inference Time: 0.13729071617126465\n",
      "Inference Time: 0.12865519523620605\n",
      "Inference Time: 0.127655029296875\n",
      "Inference Time: 0.1386258602142334\n",
      "Inference Time: 0.1231834888458252\n",
      "Inference Time: 0.12367010116577148\n",
      "Inference Time: 0.11669492721557617\n",
      "Inference Time: 0.12366938591003418\n",
      "Inference Time: 0.12445473670959473\n",
      "Inference Time: 0.11220955848693848\n",
      "Inference Time: 0.11967825889587402\n",
      "Inference Time: 0.1136925220489502\n",
      "Inference Time: 0.11668777465820312\n",
      "Inference Time: 0.12067723274230957\n",
      "Inference Time: 0.11568856239318848\n",
      "Inference Time: 0.14860248565673828\n",
      "Inference Time: 0.1431257724761963\n",
      "Inference Time: 0.14860177040100098\n",
      "Inference Time: 0.13963055610656738\n",
      "Inference Time: 0.1486368179321289\n",
      "Inference Time: 0.1935107707977295\n",
      "Inference Time: 0.22178196907043457\n",
      "Inference Time: 0.1269681453704834\n",
      "Inference Time: 0.11469292640686035\n",
      "Inference Time: 0.12267231941223145\n",
      "Inference Time: 0.17752432823181152\n",
      "Inference Time: 0.16356182098388672\n",
      "Inference Time: 0.16256475448608398\n",
      "Inference Time: 0.13164520263671875\n",
      "Inference Time: 0.14411258697509766\n",
      "Inference Time: 0.13514924049377441\n",
      "Inference Time: 0.11669349670410156\n",
      "Inference Time: 0.13336920738220215\n",
      "Inference Time: 0.1100924015045166\n",
      "Inference Time: 0.11469292640686035\n",
      "Inference Time: 0.11121463775634766\n",
      "Inference Time: 0.1107032299041748\n",
      "Inference Time: 0.1186823844909668\n",
      "Inference Time: 0.3236417770385742\n",
      "Inference Time: 0.1216745376586914\n",
      "Inference Time: 0.1122126579284668\n",
      "Inference Time: 0.13563299179077148\n",
      "Inference Time: 0.12766075134277344\n",
      "Inference Time: 0.12865447998046875\n",
      "Inference Time: 0.14860200881958008\n",
      "Inference Time: 0.11394214630126953\n",
      "Inference Time: 0.11642003059387207\n",
      "Inference Time: 0.15358853340148926\n",
      "Inference Time: 0.16954493522644043\n",
      "Inference Time: 0.1635596752166748\n",
      "Inference Time: 0.15558767318725586\n",
      "Inference Time: 0.13870000839233398\n",
      "Inference Time: 0.11819577217102051\n",
      "Inference Time: 0.13862824440002441\n",
      "Inference Time: 0.1575789451599121\n",
      "Inference Time: 0.13364338874816895\n",
      "Inference Time: 0.11936688423156738\n",
      "Inference Time: 0.12366485595703125\n",
      "Inference Time: 0.14062166213989258\n",
      "Inference Time: 0.11668801307678223\n",
      "Inference Time: 0.13263964653015137\n",
      "Inference Time: 0.13064956665039062\n",
      "Inference Time: 0.15957403182983398\n",
      "Inference Time: 0.1620779037475586\n",
      "Inference Time: 0.11768579483032227\n",
      "Inference Time: 0.18650007247924805\n",
      "Inference Time: 0.14182400703430176\n",
      "Inference Time: 0.12244391441345215\n",
      "Inference Time: 0.18652725219726562\n",
      "Inference Time: 0.15358519554138184\n",
      "Inference Time: 0.12067675590515137\n",
      "Inference Time: 0.1186821460723877\n",
      "Inference Time: 0.1296525001525879\n",
      "Inference Time: 0.1466066837310791\n",
      "Inference Time: 0.15558290481567383\n",
      "Inference Time: 0.15059661865234375\n",
      "Inference Time: 0.15858197212219238\n",
      "Inference Time: 0.13828277587890625\n",
      "Inference Time: 0.1492609977722168\n",
      "Inference Time: 0.2783198356628418\n",
      "Inference Time: 0.4119265079498291\n",
      "Inference Time: 0.24434566497802734\n",
      "Inference Time: 0.16057300567626953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Time: 0.11420536041259766\n",
      "Inference Time: 0.1132044792175293\n",
      "Inference Time: 0.14162015914916992\n",
      "Inference Time: 0.12566280364990234\n",
      "Inference Time: 0.12923550605773926\n",
      "Inference Time: 0.11437034606933594\n",
      "Inference Time: 0.14064931869506836\n",
      "Inference Time: 0.11967706680297852\n",
      "Inference Time: 0.1107029914855957\n",
      "Inference Time: 0.11868119239807129\n",
      "Inference Time: 0.14860272407531738\n",
      "Inference Time: 0.12366771697998047\n",
      "Inference Time: 0.13164734840393066\n",
      "Inference Time: 0.11269998550415039\n",
      "Inference Time: 0.1595747470855713\n",
      "Inference Time: 0.1675574779510498\n",
      "Inference Time: 0.1396341323852539\n",
      "Inference Time: 0.13115978240966797\n",
      "Inference Time: 0.13563823699951172\n",
      "Inference Time: 0.21342825889587402\n",
      "Inference Time: 0.1685476303100586\n",
      "Inference Time: 0.1436150074005127\n",
      "Inference Time: 0.1266627311706543\n",
      "Inference Time: 0.15309977531433105\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now().strftime('%Y%d%m_%H%M%S')\n",
    "with open(CSV_PATH + now + '.csv', 'w') as f:\n",
    "    for image, filename in zip(dataset, file_list):\n",
    "        image = image[tf.newaxis, ...] # HWC -> NHWC\n",
    "        \n",
    "        a = time.time()\n",
    "        predict = model.predict(image)[0][0]\n",
    "        print('Inference Time:', time.time() - a)\n",
    "        \n",
    "        if predict > THRES_LEVEL:\n",
    "            label = 'FAIL'\n",
    "        else:\n",
    "            label = 'OK'\n",
    "        \n",
    "        f.write(','.join([filename, label, str(predict)]) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
